{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](table_of_contents.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1.  The Unit Circle $S^1$: Kinematics, Control, and Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Definitions and Notation](#Definitions-and-Notation)\n",
    "1. [Kinematics](#Kinematics)\n",
    "  - [Exponential and Logarithmic Maps](#Exponential-and-Logarithmic-Maps)\n",
    "1. [Optimization](#Optimization)\n",
    "1. [Differential Equation Solvers](#Differential-Equation-Solvers)\n",
    "1. [PID Control](#PID Control)\n",
    "1. [Optimal Control on SO(2)](#Optimal Control on SO(2))\n",
    "1. [Estimation](#Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin the study of Lie Groups and Lie Algebras by studying differential equations defined on the unit circle in $\\mathbb{R}^2$.  Note that the unit circle in $\\mathbb{R}^2$ is a one dimensional manifold embedded in the two dimensional Euclidean space $\\mathbb{R}^2$. Two spaces are said to be isomorphic if there is a differentiable one-to-one mapping between elements in each space.  Note that $\\mathbb{R}^2$ is isomorphic to the complex plane $\\mathbb{C}$ by equating the $x$-axis with the real line and the $y$-axis with the imaginary line.  In $\\mathbb{R}^2$ the unit circle is given by $S^1 = \\{ (x_1, x_2)\\in\\mathbb{R}^2: x_1^2+x_2^2=1\\}$.  In the complex plane, the unit circle is the set $S^1 = \\{z\\in\\mathbb{C}: |z|=1\\}$.  Since any complex number $z\\in\\mathbb{C}$ can be written in rectangular form as $z=a+jb$ and in polar form as $z=me^{j\\theta}=m\\cos\\theta +jm\\sin\\theta$, the unit circle can be alternatively represented as $S^1 = \\{e^{j\\theta}\\in\\mathbb{C}: \\theta\\in(-\\pi, pi]\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the set of 2x2 matrices $\\mathcal{M} = \\left\\{\\begin{pmatrix} a & -b \\\\ b & a\\end{pmatrix}: a,b \\in \\mathbb{R} \\right\\}\\subset \\mathbb{R}^{2\\times 2}$.  It is clear that the complex plane $\\mathbb{C}$ is isomorphic to $\\mathcal{M}$ since for every complex number $z=a+jb$ there is unique element in $\\mathcal{M}$, and visa versa.  It turns out that multiplying complex numbers is equivalent to matrix multiplication over $\\mathcal{M}$. As can be seen from simple algebra:\n",
    "\\begin{align*}\n",
    "(a+jb)(c+jd) &= (ac-bd) + j(bc+ad) \\\\\n",
    "\\begin{pmatrix} a & -b \\\\ b & a \\end{pmatrix} \\begin{pmatrix} c & -d \\\\ d & c \\end{pmatrix} &= \\begin{pmatrix} ac-bd & -(bc+ad) \\\\ (bc+ad) & ac-bd \\end{pmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "In fact, define $I=\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}\\subset\\mathcal{M}$ and $J=\\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}\\subset\\mathcal{M}$ and note that $I^2=I$, $IJ=JI=J$ and $J^2=-I$.  Therefore $I$ acts like the complex number $1$, and $J$ acts like the complex number $j=\\sqrt{-1}$.  Any element of $\\mathcal{M}$ can be written as $aI+bJ$ in the same way that any element of the complex plane $\\mathbb{C}$ can be written as $a+jb$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unit circle embedded in the complex plane is given by the set $S^1=\\{ z\\in\\mathbb{C}: |z|=1\\}$.  Similarly, the unit circle embedded in the set of $2\\times 2$ matrices $\\mathbb{R}^{2\\times 2}$ is given by $S^1=\\{G\\in\\mathcal{M}: \\det{G}=1\\}$.  \n",
    "\n",
    "For example, the point $x=(1/\\sqrt{2}, 1/\\sqrt{2})^\\top$ represent a point on the unit circle in $\\mathbb{R}^2$ that is equivalent to the representation $z=e^{j\\frac{\\pi}{4}}$ in $\\mathbb{C}$, that is equivalent to the representation $G=\\begin{pmatrix}\\frac{1}{\\sqrt{2}}& -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}}\\end{pmatrix}$ in $\\mathbb{R}^{2\\times 2}$.\n",
    "\n",
    "Therefore, we can talk of embeddings \n",
    "\\begin{align*}\n",
    "\\pi_1: S^1 &\\rightarrow \\mathbb{R}^2, \\\\\n",
    "\\pi_2: S^1 &\\rightarrow \\mathbb{C}, \\\\\n",
    "\\pi_3: S^1 &\\rightarrow \\mathbb{R}^{2\\times 2}.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $R$ is said to be orthgonal if $R^\\top R = RR^\\top = I$.  The set of $2\\times 2$ orthogonal matrices is denoted $O(2)$.  Orthogonal matries can have determinant equal to $\\pm 1$.  The set of orthogonal matrices with determinant equal to 1 is denoted $SO(2)$ and is the called the special orthogonal group.  It is fairly straight forward to show that $SO(2)=\\{G\\in\\mathcal{M}: det(G)=1\\}$ and is therefore isomorphic to $S^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code establishes a class for $S^1$.  We will use matrices in $\\mathbb{R}^{2\\times 2}$ as the native representation for elements of $S^1$ and provide functions that convert between the representations.  Since $S^1$ is isomorphic to $SO(2)$ and since we will generalize $SO(3)$ later, the discussion that follows will focus on $SO(2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class lie_group_SO2:\n",
    "    # this class will be used to define operations on SO2\n",
    "    def __init__(self, G=np.eye(2)):\n",
    "        self.mat = G\n",
    "    \n",
    "    # generate a random element in SO2\n",
    "    def gen_random_element(self):\n",
    "        th = random.uniform(-np.pi, np.pi)\n",
    "        self.mat = np.array([[np.cos(th), -np.sin(th)], [np.sin(th), np.cos(th)]])\n",
    "    \n",
    "    # functions that convert between representations\n",
    "    def vector(self):\n",
    "        return self.mat[:,0]\n",
    "\n",
    "    def complex(self):\n",
    "        return self.mat[0,0] + self.mat[1,0]*1j   \n",
    "    \n",
    "    def magPhase(self):\n",
    "        mag = np.sqrt(self.mat[0,0]**2 + self.mat[1,0]**2)\n",
    "        phase = np.arctan2(self.mat[1,0], self.mat[0,0])\n",
    "        return mag, phase\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code tests these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = lie_group_SO2()\n",
    "G1.gen_random_element()\n",
    "print('G=', G1.mat)\n",
    "x = G1.vector()\n",
    "print('x=', x)\n",
    "z = G1.complex()\n",
    "print('z=', z)\n",
    "mag, phase = G1.magPhase()\n",
    "print('mag = ', mag, ', phase = ', 2*np.pi*phase, 'deg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematics, a group is defined as a set of objects $\\mathcal{G}$ that contains a unique element $I\\in\\mathcal{G}$ called the identity, and an operation $\\cdot$ such that \n",
    "*  $G_1, G_2 \\in \\mathcal{G}$ implies that $G_1\\cdot G_2 \\in \\mathcal{G}$,\n",
    "*  For every $G\\in\\mathcal{G}$ there exists and element $H\\in\\mathcal{G}$ such that $G\\cdot H = H\\cdot G = I$.  $H$ is called the inverse of $G$ and will be denoted as $G^{-1}$.\n",
    "\n",
    "The first item implies that $\\mathcal{G}$ is closed under the $\\cdot$ operation.  The second item implies that every element in $\\mathcal{G}$ has an inverse.\n",
    "\n",
    "For $S^1$, the $\\cdot$ operator is defined differently depending on the space into which it is embedded.  For example, in $\\mathbb{C}$, let $z_1=e^{j\\theta_1}$ and $z_2=e^{j\\theta^2}$, then clearly \n",
    "\\begin{equation}\n",
    "z = z_1 z_2 = e^{j\\theta_1} e^{j\\theta_2} = e^{j(\\theta_1+\\theta)}\n",
    "\\end{equation}\n",
    "is an element of $S^1$, and if $z=1+j0$ is the identity, then the inverse operator is simply the complex conjugate since\n",
    "\\begin{equation}\n",
    "z\\bar{z} = e^{j\\theta} e^{-j\\theta} = e^{j(\\theta-\\theta)} = e^{j0} = 1.\n",
    "\\end{equation}\n",
    "\n",
    "On the other hand, if $S^1$ is embedded in $\\mathbb{R}^{2\\times 2}$, and the identity is defined as the identity matrix, then the $\\cdot$ operator is simply matrix multiplication since\n",
    "\\begin{align*}\n",
    "G_1 G_2 &= \\begin{pmatrix} \\cos(\\theta_1) & -\\sin(\\theta_1) \\\\ \\sin(\\theta_1) & \\cos(\\theta_1) \\end{pmatrix}\n",
    "\\begin{pmatrix} \\cos(\\theta_2) & -\\sin(\\theta_2) \\\\ \\sin(\\theta_2) & \\cos(\\theta_2) \\end{pmatrix} \\\\\n",
    "&= \\begin{pmatrix} \\cos(\\theta_1)\\cos(\\theta_1)-\\sin(\\theta_1)\\sin(\\theta_2) & -\\cos(\\theta_1)\\sin(\\theta_2)-\\sin(\\theta_1)\\cos(\\theta_2) \\\\ \\cos(\\theta_1)\\sin(\\theta_2)+\\sin(\\theta_1)\\cos(\\theta_2) & \\cos(\\theta_1)\\cos(\\theta_1)-\\sin(\\theta_1)\\sin(\\theta_2) \\end{pmatrix} \\\\\n",
    "&= \\begin{pmatrix} \\cos(\\theta_1+\\theta_2) & -\\sin(\\theta_1+\\theta_2) \\\\ \\sin(\\theta_1+\\theta_2) & \\cos(\\theta_1+\\theta_2) \\end{pmatrix}\n",
    "\\end{align*}\n",
    "and the inverse of $G\\in\\mathcal{G}$ is given by the matrix inverse since $GG^{-1}=I$.  \n",
    "\n",
    "It should be clear that if $S^1$ is embedded in $\\mathbb{R}^2$ the $\\cdot$ and inverse operators are much more complex.  Since operations on the group $S^1$ can be carried out with matrix operations, the most convenient representation will be in $\\mathbb{R}^{2\\times 2}$.   (Actually, $\\mathbb{C}$ is convenient for $S^1$ but does not extend to other groups, whereas matrix operations will extend to other groups useful in robotics.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expand the python class to include an identity, the dot and the inverse operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lie_group_SO2(lie_group_SO2):\n",
    "    \n",
    "    # compose (multiply) two elements in SO2\n",
    "    def dot(self, G1):\n",
    "        return np.dot(self.mat, G1)\n",
    "    \n",
    "    # return the identity element\n",
    "    def identity():\n",
    "        return np.eye(2)\n",
    "\n",
    "    # return the inverse of an element in SO(2)\n",
    "    def inverse(self):\n",
    "        return self.mat.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines test the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = lie_group_SO2()\n",
    "G.gen_random_element()\n",
    "print('G=', G.mat)\n",
    "print('G^{-1}=', G.inverse())\n",
    "G1 = lie_group_SO2()\n",
    "G1.gen_random_element()\n",
    "print('G*G1=', G.dot(G1.mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinematics\n",
    "\n",
    "From the above discussion, it is clear that $G\\in SO(2)$ implies that $G=\\begin{pmatrix}\\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix}$.  Suppose now that $\\theta\\equiv\\theta(t)$ is a function of time, then\n",
    "\\begin{equation*}\n",
    "G(t) = \\begin{pmatrix} \\cos\\theta(t) & -\\sin\\theta(t) \\\\ \\sin\\theta(t) & \\cos\\theta(t)\\end{pmatrix}.\n",
    "\\end{equation*}\n",
    "\n",
    "Taking the derivative with respect to time we get\n",
    "\\begin{align}\n",
    "\\dot{G} &= \\begin{pmatrix} -\\dot{\\theta}\\sin\\theta & -\\dot{\\theta}\\cos\\theta \\\\ \\dot{\\theta}\\cos\\theta & -\\dot{\\theta}\\sin\\theta \\end{pmatrix} \\\\\n",
    "&= \\begin{pmatrix} \\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix} \n",
    "   \\begin{pmatrix} 0 & -\\dot{\\theta} \\\\ \\dot{\\theta} & 0 \\end{pmatrix} \\\\\n",
    "&= G\\dot{\\theta}^\\wedge,\n",
    "\\end{align}\n",
    "where we define\n",
    "\\begin{equation*}\n",
    "\\dot{\\theta}^\\wedge = \\begin{pmatrix} 0 & -\\dot{\\theta} \\\\ \\dot{\\theta} & 0 \\end{pmatrix} = J\\dot{\\theta}.\n",
    "\\end{equation*}\n",
    "\n",
    "The kinematic equation of motion on $SO(2)$ is therefore given by $\\dot{G} = G\\dot{\\theta}^{\\wedge}$\n",
    "\n",
    "Note that in $\\mathbb{R}^2$, the tangent to the unit circle at the point $(1,0)$ is a vertical line given by $\\ell = \\{\\sigma\\begin{pmatrix} 0 \\\\ 1\\end{pmatrix}: \\sigma\\in\\mathbb{R}\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "plt.plot(np.cos(theta), np.sin(theta))\n",
    "S = 3\n",
    "tangent_plane = np.column_stack((np.ones(100), np.linspace(-S, S, 100))) \n",
    "plt.plot(tangent_plane[:,0], tangent_plane[:,1])\n",
    "lie_alg = np.column_stack((0.*np.ones(100), np.linspace(-S, S, 100))) \n",
    "plt.plot(lie_alg[:,0], lie_alg[:,1], color='red')\n",
    "plt.text(1.25, 0, '$I$', fontsize=14)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.axis((-S, S, -S, S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tangent plane is shown in orange and the Lie algebra, which is a subspace of $\\mathbb{R}^2$ is shown in red.  When $G$ is not the identity, then the tangent plane and its tangent space is shown in the plot below.  Note that the tangent space is a rotated (transformed) version of the Lie algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "plt.plot(np.cos(theta), np.sin(theta))\n",
    "S = 3\n",
    "th = 60*np.pi/180.\n",
    "G = np.array([[np.cos(th), -np.sin(th)],[np.sin(th), np.cos(th)]])\n",
    "tangent_plane = np.column_stack((np.ones(100), np.linspace(-S, S, 100))) \n",
    "tangent_plane = np.dot(G, tangent_plane.T).T\n",
    "plt.plot(tangent_plane[:,0], tangent_plane[:,1])\n",
    "lie_alg = np.column_stack((0.*np.ones(100), np.linspace(-S, S, 100))) \n",
    "tangent_space = np.dot(G, lie_alg.T).T\n",
    "plt.plot(tangent_space[:,0], tangent_space[:,1], color='red')\n",
    "plt.text(0.5, 1.0, '$G$', fontsize=14)\n",
    "plt.axis('equal')\n",
    "plt.grid(True)\n",
    "plt.axis((-S, S, -S, S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the complex plane $\\mathbb{C}$, the tangent to $S^1$ at the identity $z=1+0j$ is the vertical line $\\ell = \\{ \\sigma j: \\sigma\\in\\mathbb{R}\\}$.  In the set of $2\\times 2$ matrices, the tangent to $S^1=SO(2)$ at the identity $G=I$ is the vertical line $\\ell = \\{\\sigma\\begin{pmatrix} 0 & -1 \\\\ 1 & 0 \\end{pmatrix}: \\sigma\\in\\mathbb{R}\\} = \\{\\sigma J: \\sigma\\in\\mathbb{R}\\}$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tangent space at the identity $G=I$ is called the Lie Algebra.  \n",
    "\n",
    "The Lie algebra of $SO(2)$ will be denoted ${\\mathfrak so}(2)$ and in $\\mathbb{R}^{2\\times 2}$ is given by\n",
    "\\begin{equation}\n",
    "{\\mathfrak so}(2) = \\{ \\sigma J: \\sigma\\in\\mathbb{R}\\}\n",
    "\\end{equation}\n",
    "\n",
    "In $\\mathbb{R}^{2\\times 2}$, the Lie bracket is the standard matrix Lie bracket defined as $[A,B]=AB-BA$, where $A,B\\in so(2)$.  Note that since $A,B\\in so(2)$ that we can write $A=aJ$ and $B=bJ$ and therefore\n",
    "\\begin{align*}\n",
    "[A,B] &= AB - BA \\\\\n",
    "      &= (aJ)(bJ)-(bJ)(aJ) \\\\\n",
    "      &= (-abI) - (-baI)\\\\\n",
    "      &= 0.\n",
    "\\end{align*}\n",
    "Therefore, the Lie bracket on $so(2)$ is always zeros.  Lie groups whose Lie bracket is always zero are called Abelian Lie groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tangent space at an element that is not equal to identity, is just a transformed version of the Lie algebra ${\\mathfrak so}(2)$.  Since $\\dot{G}=G\\omega^{\\wedge}$, the tangent space at G is $G\\omega^{\\wedge}=GJ\\omega$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential and Logarithmic Maps\n",
    "We have shown that the kinematic equation of motion on $SO(2)$ can be written as \n",
    "\\begin{equation}\n",
    "\\dot{G} = G\\omega^\\wedge.\n",
    "\\end{equation}\n",
    "Rearranging we get $\\dot{G}-G\\omega^\\wedge=0$.  Multiplying both sides of the equation by the integrating factor $e^{-\\omega^\\wedge}$ gives\n",
    "\\begin{equation}\n",
    "(\\dot{G} - G\\omega^\\wedge)e^{-\\omega^\\wedge} = 0,\n",
    "\\end{equation}\n",
    "which implies that \n",
    "\\begin{equation}\n",
    "\\frac{d}{dt}Ge^{-\\omega^\\wedge} = 0.\n",
    "\\end{equation}\n",
    "Integrating both sides from $0$ to $t$ gives\n",
    "\\begin{equation}\n",
    "G(t) = G(0)e^{\\omega^\\wedge t}.\n",
    "\\end{equation}\n",
    "Since $\\omega^\\wedge t = J\\omega t$, the exponential function maps the Lie algebra ${\\mathfrak so}(2)$ to the Lie group $SO(2)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $SO(2)$ there is a simple formula for the exponential map $e^{J\\sigma}$ since $J^2=-I$ we have\n",
    "\\begin{align*}\n",
    "e^{J\\sigma} &= I + J\\sigma + \\frac{1}{2!}J^2\\sigma^2 + \\frac{1}{3!}J^3\\sigma^3 + \\frac{1}{4!}J^4\\sigma^4 + \\cdots \\\\\n",
    "&=(1-\\frac{1}{2!}\\sigma^2 + \\frac{1}{4!}\\sigma^4 + \\cdots)I + (\\sigma - \\frac{1}{3!}\\sigma^3 + \\frac{1}{5!}\\sigma^5+\\cdots)J \\\\\n",
    "&=\\cos\\sigma I + \\sin\\sigma J \\\\\n",
    "&=\\begin{pmatrix}\\cos\\sigma & -\\sin\\sigma \\\\ \\sin\\sigma & \\cos\\sigma \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "Therefore the map $exp: {\\mathfrak so}(2)\\rightarrow SO(2)$ is periodic and is not one-to-one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the logarithm maps the Lie group to the Lie algebra as $\\log:SO(2)\\rightarrow {\\mathfrak so}(2)$ and is defined as\n",
    "\\begin{equation}\n",
    "\\log\\begin{pmatrix}\\cos\\theta & -\\sin\\theta \\\\ \\sin\\theta & \\cos\\theta \\end{pmatrix} = (\\theta + 2\\pi n)J.\n",
    "\\end{equation}\n",
    "Alternatively, we could write\n",
    "\\begin{equation}\n",
    "\\log(G) = (\\vartheta + 2\\pi n)J, \\quad \\text{where} \\quad \\vartheta = \\tan^{-1}\\left(\\frac{G_{21}}{G_{11}}\\right).\n",
    "\\end{equation}\n",
    "We can add Python methods implement the logarithmic and exponential maps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lie_group_SO2(lie_group_SO2):\n",
    "    \n",
    "    # Exponential of g in so(2)\n",
    "    def exp(self, g):\n",
    "        # check to see of g is in so(2)\n",
    "        if np.linalg.norm(g+g.T)<.000001:\n",
    "            th = g[1,0]\n",
    "            G = np.array([[np.cos(th), -np.sin(th)], [np.sin(th), np.cos(th)]])\n",
    "            return G\n",
    "        else:\n",
    "            print('g is not in so(2)')\n",
    "    \n",
    "    # log of G in SO(2)\n",
    "    def log(self):\n",
    "        # check to see if G is in SO(2)\n",
    "        if np.linalg.norm(np.dot(self.mat, self.mat.T)-np.eye(2))<.000001:\n",
    "            varphi = np.arctan2(self.mat[1,0],self.mat[0,0])\n",
    "            g = np.array([[0, -varphi], [varphi, 0]])\n",
    "            return g\n",
    "        else:\n",
    "            print('G is not in SO(2)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random element in SO(2)\n",
    "G = lie_group_SO2()\n",
    "G.gen_random_element()\n",
    "print('G=', G.mat)\n",
    "# map to so(2) through the log\n",
    "g = G.log()\n",
    "print('g=', g)\n",
    "# map back to SO(2) through the exp\n",
    "H = G.exp(g)\n",
    "print('H=', H)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization (Gradient Descent) on $S^1$\n",
    "\n",
    "This section follows http://www.seas.upenn.edu/~cjtaylor/PUBLICATIONS/pdfs/TaylorTR94b.pdf\n",
    "\n",
    "Suppose that a camera is rotated in place by an able of $\\theta$ and collects a set of corresponding points at both orientations.  Let $\\{\\mathbf{p}_i^0\\}_{i=1}^N$ and $\\{\\mathbf{p}_i^1\\}_{i=1}^N$ be the corresponding points in frame $0$ and frame $1$, as shown in the figure below for a single point.\n",
    "\n",
    "<img src=\"files/rotation_optimization.png\" width=\"300\">\n",
    "\n",
    "Let $R\\in SO(2)$ be the rotation matrix from frame $0$ to frame $1$.  Then, we should have that $\\mathbf{p}^1 = R\\mathbf{p}^0$.  Since the inner product $<x, y> = y^\\top x$ is maximized when $x=y$, we have that $<R\\mathbf{p}^0, \\mathbf{p}^1> = (\\mathbf{p}^1)^\\top R \\mathbf{p}^0$ is maximized over all $R$ when $R$ is the correct rotation matrix. \n",
    "\n",
    "If the corresponding image points have noise, then the objective may be to solve the following optimization problem:\n",
    "\\begin{equation} \\label{eq:opt_S1}\n",
    "R^\\ast = \\arg\\max_R \\sum_{i=1}^N \\left[ (\\mathbf{p}_i^1)^\\top R \\mathbf{p}_i^0 \\right]^2.\n",
    "\\end{equation}\n",
    "\n",
    "Equation \\eqref{eq:opt_S1} is an example of an optimization problem over $SO(2)$.\n",
    "\n",
    "We will show how to construct a Gauss-Newton iteration algorithm to solve this optimization problem.  The basic idea is to parameterize the rotation matrix $R\\in SO(2)$ at the $k^{th}$ iteration as \n",
    "\\begin{equation}\n",
    "R_k = R_{k-1} e^{J\\omega_k}.\n",
    "\\end{equation}\n",
    "The cost function can then be written as \n",
    "\\begin{align}\n",
    "V(\\omega_k) &= \\sum_{i=1}^N \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]^2 \\\\\n",
    "    &\\approx V(0) + \\left(\\frac{\\partial V}{\\partial \\omega_k}\\Big|_{\\omega_k=0}\\right)^\\top \\omega_k + \\omega_k^\\top \\left(\\frac{\\partial^2 V}{\\partial \\omega_k^2}\\Big|_{\\omega_k=0}\\right)\\omega_k.\n",
    "    \\label{eq:cost_quadratic_approx}\n",
    "\\end{align}\n",
    "The Guauss-Newton step that maximizes \\eqref{eq:cost_quadratic_approx} is therefore\n",
    "$$\n",
    "\\omega_k = \\frac{\\gamma}{2} \\left(\\frac{\\partial^2 V}{\\partial \\omega_k^2}\\Big|_{\\omega_k=0}\\right)^{-1}\\left(\\frac{\\partial V}{\\partial \\omega_k}\\Big|_{\\omega_k=0}\\right),\n",
    "$$\n",
    "where\n",
    "\\begin{align*}\n",
    "\\frac{\\partial V}{\\partial \\omega_k}\\Big|_{\\omega_k=0} &= \n",
    "\\frac{\\partial }{\\partial \\omega_k}\\Big|_{\\omega_k=0}\\left[\\sum_{i=1}^N \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]^2 \\right] \\\\\n",
    "&= 2\\sum_{i=1}^N \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]  \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}\\frac{\\partial e^{J\\omega_k}}{\\partial \\omega_k}\\Big|_{\\omega_k=0} \\mathbf{p}_i^0 \\right] \\\\\n",
    "&= 2\\sum_{i=1}^N \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]  \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}J \\mathbf{p}_i^0 \\right]\n",
    "\\end{align*}\n",
    "since\n",
    "\\begin{align*}\n",
    "\\frac{\\partial e^{J\\omega_k}}{\\partial \\omega_k}\\Big|_{\\omega_k=0} &=\n",
    "\\frac{\\partial }{\\partial \\omega_k}\\Big|_{\\omega_k=0}\\left[I + J\\omega_k + \\frac{1}{2!}J^2\\omega_k^2 + \\cdots \\right] \\\\\n",
    "&= \\left[J + J^2\\omega_k + \\frac{1}{2!}J^3\\omega_k^2\\right]_{\\omega_k=0} \\\\\n",
    "&= Je^{J\\omega_k}\\Big|_{\\omega_k=1} = J\n",
    "\\end{align*}\n",
    "and\n",
    "\\begin{align*}\n",
    "\\frac{\\partial^2 V}{\\partial \\omega_k^2}\\Big|_{\\omega_k=0} &= \n",
    "\\frac{\\partial }{\\partial \\omega_k}\\Big|_{\\omega_k=0}\\left[2\\sum_{i=1}^N \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]  \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}Je^{J\\omega_k} \\mathbf{p}_i^0 \\right] \\right]\\\\\n",
    "&= \n",
    "2\\sum_{i=1}^N \\left\\{ \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]  \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}J\\frac{\\partial e^{J\\omega_k}}{\\partial \\omega_k}\\Big|_{\\omega_k=0} \\mathbf{p}_i^0 \\right] + \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}\\frac{\\partial e^{J\\omega_k}}{\\partial \\omega_k}\\Big|_{\\omega_k=0} \\mathbf{p}_i^0 \\right]  \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}Je^{J\\omega_k} \\mathbf{p}_i^0 \\right] \\right\\} \\\\\n",
    "&= \n",
    "2\\sum_{i=1}^N \\left\\{ \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}e^{J\\omega_k} \\mathbf{p}_i^0 \\right]  \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}J^2 \\mathbf{p}_i^0 \\right] + \\left[ (\\mathbf{p}_i^1)^\\top R_{k-1}J \\mathbf{p}_i^0 \\right]^2\\right\\}.\n",
    "\\end{align*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization on $SO\\left(2\\right)$ \n",
    "\n",
    "Suppose we have ground robot equipped with some kind of sensor like\n",
    "a LIDAR or Intel RealSense camera that can measure direction and distance\n",
    "measurements to landmarks as shown in the following figure. Using\n",
    "these measurements, we can estimate the unknown rotation and translation\n",
    "by optimization between measurements. The $i^{th}$ landmark vector\n",
    "measured in frame $b$ is defined in terms of the frame $a$ measurement\n",
    "by\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf l}_{i}^{b}=R_{a}^{b}{\\bf l}_{i}^{a}+{\\bf t}^{b},\n",
    "\\end{equation}\n",
    "where ${\\bf t}^{b}$ is the robot translation from frame $a$ to frame\n",
    "$b$ in frame $b$ and $R_{a}^{b}$ is the passive rotation from frame\n",
    "$a$ to frame $b$. Likewise, the $i^{th}$ landmark measurement in\n",
    "frame $a$ may given in terms of the frame $b$ measurement by\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf l}_{i}^{a}=\\left(R_{a}^{b}\\right)^{\\top}\\left({\\bf l}_{i}^{b}-{\\bf t}^{b}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "The residual error due to rotation and translation of the $i^{th}$\n",
    "landmark may be given by moving everything to one side of either of\n",
    "the previous two equations and pre-multiplying by itself to get a\n",
    "scalar. There could be a nice way to combine these two error equations\n",
    "because the error may differ between them, but we'll just pick one\n",
    "for now. We will use the first because its derivatives are slightly\n",
    "more simple, which gives the residual error\n",
    "\n",
    "\\begin{equation}\n",
    "r_{i}=\\frac{1}{2}{\\bf e}^{\\top}{\\bf e},\n",
    "\\end{equation}\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf e}={\\bf l}_{i}^{b}-R_{a}^{b}{\\bf l}_{i}^{a}-{\\bf t}^{b}.\n",
    "\\end{equation}\n",
    "\n",
    "Since each landmark measurement is noisy, we can treat this as a nonlinear\n",
    "least squares problem and solve for the rotation and translation that\n",
    "gives us the lowest square error over all of the landmark measurements\n",
    "with the Gauss-Newton algorithm. To do this, we need the Jacobian\n",
    "of the residual error with respect to each variable. The derivative\n",
    "of the residual error w.r.t. translation is straightforward and is\n",
    "given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial r_{i}}{\\partial{\\bf t}^{b}}={\\bf e}^{\\top}\\frac{\\partial{\\bf e}}{\\partial{\\bf t}^{b}},\n",
    "\\end{equation}\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial{\\bf e}}{\\partial{\\bf t}^{b}}=-I.\n",
    "\\end{equation}\n",
    "We can find the derivatives with respect to change in rotation on\n",
    "the manifold by taking limits. Elements of $SO\\left(2\\right)$ are\n",
    "not vectors, so we cannot directly perform addition with them. Let's\n",
    "define a new type of addition operator by \n",
    "\n",
    "\\begin{align}\n",
    "\\boxplus & :SO\\left(2\\right)\\times\\mathbb{R}^{1}\\rightarrow SO\\left(2\\right),\\\\\n",
    "R\\boxplus\\delta & =\\exp\\left(-\\delta^{\\times}\\right)R,\n",
    "\\end{align}\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta^{\\times}=\\begin{bmatrix}0 & -\\delta\\\\\n",
    "\\delta & 0\n",
    "\\end{bmatrix}.\n",
    "\\end{equation}\n",
    "\n",
    "The derivative w.r.t. rotation of the error is then given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial r_{i}}{\\partial R}={\\bf e}^{\\top}\\frac{\\partial{\\bf e}}{\\partial R},\n",
    "\\end{equation}\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial{\\bf e}}{\\partial R} & =\\lim_{\\epsilon\\rightarrow0}\\frac{1}{\\epsilon}\\left[\\left({\\bf l}_{i}^{b}-\\left(R_{a}^{b}\\boxplus\\epsilon\\right){\\bf l}_{i}^{a}+{\\bf t}^{b}\\right)-\\left({\\bf l}_{i}^{b}-R_{a}^{b}{\\bf l}_{i}^{a}+{\\bf t}^{b}\\right)\\right]\\\\\n",
    " & =\\lim_{\\epsilon\\rightarrow0}\\frac{1}{\\epsilon}\\left[-\\left(\\exp\\left(-{\\bf 1}^{\\times}\\epsilon\\right)R_{a}^{b}\\right){\\bf l}_{i}^{a}+R_{a}^{b}{\\bf l}_{i}^{a}\\right]\\\\\n",
    " & =\\lim_{\\epsilon\\rightarrow0}\\frac{1}{\\epsilon}\\left[-\\left(\\left(I-{\\bf 1}^{\\times}\\epsilon\\right)R_{a}^{b}\\right){\\bf l}_{i}^{a}+R_{a}^{b}{\\bf l}^{a}\\right]\\\\\n",
    " & =\\lim_{\\epsilon\\rightarrow0}\\frac{1}{\\epsilon}\\left[-\\left(R_{a}^{b}-{\\bf 1}^{\\times}R_{a}^{b}\\epsilon\\right){\\bf l}_{i}^{a}+R_{a}^{b}{\\bf l}_{i}^{a}\\right]\\\\\n",
    " & =\\lim_{\\epsilon\\rightarrow0}\\frac{1}{\\epsilon}\\left[-R_{a}^{b}{\\bf l}_{i}^{a}+{\\bf 1}^{\\times}R_{a}^{b}{\\bf l}_{i}^{a}\\epsilon+R_{a}^{b}{\\bf l}_{i}^{a}\\right]\\\\\n",
    " & =\\lim_{\\epsilon\\rightarrow0}\\frac{1}{\\epsilon}\\left[{\\bf 1}^{\\times}R_{a}^{b}{\\bf l}_{i}^{a}\\epsilon\\right]\\\\\n",
    " & ={\\bf 1}^{\\times}R_{a}^{b}{\\bf l}_{i}^{a}.\n",
    "\\end{align}\n",
    "\n",
    "The Gauss-Newton algorithm is explained well on its wikipeida page https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm. Gauss-Newton can give us an update vector for $N$ landmark measurement\n",
    "matches between frames by\n",
    "\n",
    "\\begin{equation}\n",
    "\\boldsymbol{\\delta}=-\\left(J^{\\top}J\\right)^{-1}J^{\\top}{\\bf r},\n",
    "\\end{equation}\n",
    "where\n",
    "\n",
    "\\begin{align}\n",
    "J & =\\begin{bmatrix}\\frac{\\partial r_{1}}{\\partial R} & \\frac{\\partial r_{1}}{\\partial t_{x}} & \\frac{\\partial r_{1}}{\\partial t_{y}}\\\\\n",
    "\\vdots & \\vdots & \\vdots\\\\\n",
    "\\frac{\\partial r_{N}}{\\partial R} & \\frac{\\partial r_{N}}{\\partial t_{x}} & \\frac{\\partial r_{N}}{\\partial t_{y}}\n",
    "\\end{bmatrix}\\\\\n",
    "{\\bf r} & =\\begin{bmatrix}r_{1} & \\cdots & r_{N}\\end{bmatrix}^{\\top}.\n",
    "\\end{align}\n",
    "The rotation estimate is updated with the first element of $\\boldsymbol{\\delta}$\n",
    "and translation with the second two elements by\n",
    "\n",
    "\\begin{align}\n",
    "R_{n+1} & =R_{n}\\boxplus\\delta_{1}\\\\\n",
    "{\\bf t}_{n+1} & ={\\bf t}_{n}+\\begin{bmatrix}\\delta_{2}\\\\\n",
    "\\delta_{3}\n",
    "\\end{bmatrix}.\n",
    "\\end{align}\n",
    "\n",
    "Levenberg-Marquardt optimization is a mix of Gauss-Newton and Gradient Descent because it introduces a scaling factor to adjust the step size during optimization. This prevents the optimization from getting hung up or stuck in oscillation patterns, which occurs in our Gauss-Newton optimization below. Refer to https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of Gauss-Newton and Levenberg-Marquardt on SO(2)\n",
    "from numpy import array, vstack, sin, cos, eye, zeros, arccos\n",
    "from numpy.linalg import pinv, norm\n",
    "from numpy.random import randn, seed\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# use fixed random seed for to compare results against same values\n",
    "seed(0)\n",
    "\n",
    "def skew(a):\n",
    "    return array([[0,-a],[a,0]])\n",
    "\n",
    "def R(theta):\n",
    "    return array([[cos(theta),sin(theta)],[-sin(theta),cos(theta)]])\n",
    "\n",
    "def expSO2(delta):\n",
    "    return array([[cos(delta),-sin(delta)],[sin(delta),cos(delta)]])\n",
    "\n",
    "def err(R,t,la,lb):\n",
    "    return lb - R.dot(la) - t\n",
    "\n",
    "def rerr(e):\n",
    "    return 0.5*e.transpose().dot(e)\n",
    "\n",
    "# Gauss-Newton algorithm\n",
    "def GN(R0,t0,la,lb):\n",
    "    Rhat = R0.copy()\n",
    "    that = t0.copy()\n",
    "    onex = skew(1.)\n",
    "    delta_hist = []\n",
    "    for i in range(100):\n",
    "        rlist = []\n",
    "        J = zeros([N,3])\n",
    "        for j in range(la.shape[1]):\n",
    "            # residual\n",
    "            e = err(Rhat,that,la[:,j:j+1],lb[:,j:j+1])\n",
    "            rlist += [rerr(e)]\n",
    "\n",
    "            # jacobian\n",
    "            J[j,0] = e.transpose().dot(onex.dot(Rhat).dot(la[:,j:j+1]))\n",
    "            J[j,1:] = -e.transpose()\n",
    "        r = vstack(rlist)\n",
    "\n",
    "        # update estimates\n",
    "        delta = -pinv(J).dot(r)\n",
    "        Rhat = expSO2(-delta[0,0]).dot(Rhat)\n",
    "        that += delta[1:,0:1]\n",
    "\n",
    "        # stop iterations when change is small\n",
    "        delta_mag = norm(delta)\n",
    "        delta_hist += [delta_mag]\n",
    "        if delta_mag < 1e-3: break\n",
    "    return i,Rhat,that,delta_hist\n",
    "\n",
    "# Levenberg-Marquardt algorithm\n",
    "def LM(R0,t0,la,lb):\n",
    "    Rhat = R0.copy()\n",
    "    that = t0.copy()\n",
    "    onex = skew(1.)\n",
    "    delta_hist = []\n",
    "    lam = 0.1\n",
    "    new_J = True\n",
    "    r2 = 0.\n",
    "    J = zeros([N,3])\n",
    "    H = zeros([3,3])\n",
    "    for i in range(100):\n",
    "        if new_J:\n",
    "            rlist = []\n",
    "            for j in range(N):\n",
    "                # residual\n",
    "                e = err(Rhat,that,la[:,j:j+1],lb[:,j:j+1])\n",
    "                rlist += [rerr(e)]\n",
    "\n",
    "                # jacobian\n",
    "                J[j,0] = e.transpose().dot(onex.dot(Rhat).dot(la[:,j:j+1]))\n",
    "                J[j,1:] = -e.transpose()\n",
    "            r = vstack(rlist)\n",
    "            H = J.transpose().dot(J)\n",
    "            if i == 0:\n",
    "                r2 = r.transpose().dot(r)[0,0]\n",
    "\n",
    "        # dampen the Hessian\n",
    "        H_damped = H + lam*eye(3)\n",
    "\n",
    "        # update estimates\n",
    "        delta = -pinv(H_damped).dot(J.transpose()).dot(r)\n",
    "        Rnew = expSO2(-delta[0,0]).dot(Rhat)\n",
    "        tnew = that + delta[1:,0:1]\n",
    "\n",
    "        # check squared error with new transform\n",
    "        rlist = []\n",
    "        for j in range(N):\n",
    "            e = err(Rnew, tnew, la[:, j:j + 1], lb[:, j:j + 1])\n",
    "            rlist += [rerr(e)]\n",
    "        rnew = vstack(rlist)\n",
    "        r2_new = rnew.transpose().dot(rnew)[0,0]\n",
    "\n",
    "        # check new error against the old\n",
    "        if r2_new < r2:\n",
    "            lam /= 10.\n",
    "            Rhat = Rnew.copy()\n",
    "            that = tnew.copy()\n",
    "            r2 = r2_new.copy()\n",
    "            new_J = True\n",
    "        else:\n",
    "            lam *= 10.\n",
    "            new_J = False\n",
    "\n",
    "        # stop iterations when change is small\n",
    "        delta_mag = norm(delta)\n",
    "        delta_hist += [delta_mag]\n",
    "        if delta_mag < 1e-3: break\n",
    "    return i,Rhat,that,delta_hist\n",
    "\n",
    "# landmarks, camera positions, camera attitudes\n",
    "N = 100\n",
    "lm = 2*randn(2,N)\n",
    "pa = vstack([-10.,-3.])\n",
    "pb = vstack([-9.,3.])\n",
    "Ra = R(0.2)\n",
    "Rb = R(-0.2)\n",
    "\n",
    "# true camera rotation and translation\n",
    "Rab = R(-0.4)\n",
    "tab = Rb.dot(pa - pb)\n",
    "\n",
    "# measurements from each camera\n",
    "noise_stdev = 0.1\n",
    "noise_a = noise_stdev*randn(2,N)\n",
    "noise_b = noise_stdev*randn(2,N)\n",
    "la = Ra.dot(lm - pa) + noise_a\n",
    "lb = Rb.dot(lm - pb) + noise_b\n",
    "\n",
    "# initial guesses\n",
    "R0 = eye(2)\n",
    "t0 = vstack([0.,0.])\n",
    "\n",
    "# Gauss-Newton\n",
    "gn_iters,R_gn,t_gn,gn_hist = GN(R0,t0,la,lb)\n",
    "lm_iters,R_lm,t_lm,lm_hist = LM(R0,t0,la,lb)\n",
    "\n",
    "# check error in rotations\n",
    "vec = vstack([1,0])\n",
    "vt = Rab.dot(vec)\n",
    "vgn = R_gn.dot(vec)\n",
    "vlm = R_lm.dot(vec)\n",
    "\n",
    "print(\"\\nNumber of Gauss-Newton iterations:        %d\" % gn_iters)\n",
    "print(\"Number of Levenberg-Marquardt iterations: %d\" % lm_iters)\n",
    "\n",
    "print(\"\\nGauss-Newton rotation error:        %f\" % arccos(vt.transpose().dot(vgn)))\n",
    "print(\"Levenberg-Marquardt rotation error: %f\" % arccos(vt.transpose().dot(vlm)))\n",
    "\n",
    "print(\"\\nGauss-Newton translation error:        %f\" % norm(tab-t_gn))\n",
    "print(\"Levenberg-Marquardt translation error: %f\" % norm(tab-t_lm))\n",
    "\n",
    "# plot norm of delta at each iteration\n",
    "fig = plt.figure()\n",
    "plt.plot(gn_hist,'b',label=\"GN\")\n",
    "plt.plot(lm_hist,'r',label=\"LM\")\n",
    "plt.title('Norm of estimate changes per iteration')\n",
    "plt.grid(); plt.xlabel('Iteration'); plt.ylabel('Norm of change')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Equation Solvers\n",
    "In any implementation of time-varying systems, thought must be given to numerical integration methods for finding approximate solutions to differential equations. Typical algorithms include Euler's Method and Runge-Kutta Methods (i.e., RK4). However, these classical algorithms are developed for use on flat Euclidean spaces and numerical instability issues can arise when applied to curvy manifolds such as the Lie groups relevant to robotics. For these applications, numerical Lie group integrators can be used to improve stability&mdash;especially over long time windows and for slower sampling rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivating Example\n",
    "Consider the following motivating example. A pencil is spinning on a flat table. It's configuration space is $S^1$, which represents the space of possible $1$-dimensional orientations. The pencil's angular velocity is given by $\\dot{\\theta} = \\omega(t)$, which we can measure using a nanometer-sized gyro with a sampling rate of $T_s=0.01$ seconds. Our objective is to use these angular velocity measurements to perform dead-reckoning so we can estimate the current angle of the pencil.\n",
    "\n",
    "Let's first generate samples from the gyro on our spinning pencil. We assume that the pencil starts with some initial velocity that slowly decays over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gyro_samples(w0=50, Ts=0.01, secs=5, **kwargs):\n",
    "    # number of samples\n",
    "    N = int(secs/Ts)\n",
    "    \n",
    "    # sample time vector\n",
    "    n = np.arange(N)\n",
    "\n",
    "    # generate the slowly-decaying signal\n",
    "    alpha = kwargs['alpha']\n",
    "    w = w0*np.exp(-alpha*(n*Ts))\n",
    "    \n",
    "    # Make some noise!\n",
    "    sigma = kwargs['sigma']\n",
    "    eta = sigma*np.random.randn(N)\n",
    "    \n",
    "    return w + eta\n",
    "\n",
    "# Simulation parameters\n",
    "P = {\n",
    "    # initial angular velocity\n",
    "    'w0': 50,\n",
    "    \n",
    "    # sample period\n",
    "    'Ts': 0.01,\n",
    "    \n",
    "    # duration of simulation\n",
    "    'secs': 30,\n",
    "    \n",
    "    # exponential decay parameter\n",
    "    'alpha': 0.05,\n",
    "    \n",
    "    # std dev of AWGN\n",
    "    'sigma': 0.25\n",
    "}\n",
    "\n",
    "# Generate samples of gyro measurements\n",
    "w = generate_gyro_samples(**P)\n",
    "fig = plt.figure()\n",
    "plt.plot(w)\n",
    "plt.title('Gyro Samples over time')\n",
    "plt.grid(); plt.xlabel('Sample'); plt.ylabel('Angular Velocity [rad/s]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Representation Class\n",
    "To represent the orientation, which is an element of $S^1$, the following Python class is used. Internally, we use the unit-length complex number representation of group elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1:\n",
    "    def __init__(self, theta=0):\n",
    "        # The representation of the group element\n",
    "        self.z = self.from_algebra(theta)\n",
    "        \n",
    "        # Also store the original element of the algebra\n",
    "        self.theta = theta\n",
    "    \n",
    "    def from_algebra(self, theta):\n",
    "        return np.exp(1j*theta)\n",
    "    \n",
    "    def to_algebra(self, z):\n",
    "        return np.imag(np.log(z))\n",
    "    \n",
    "    def visualize(self, trajectory=np.array([])):\n",
    "        \"\"\"Visualize the group element on its manifold\n",
    "        :param trajectory: optional list of group elements to plot\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "        n = np.linspace(0, 2*np.pi, 100)\n",
    "        plt.plot(np.cos(n), np.sin(n))\n",
    "        plt.axis('square'), plt.axis([-2, 2, -2, 2]), plt.axis('off')\n",
    "        \n",
    "        if not trajectory.size:\n",
    "            trajectory = np.array([self.z])\n",
    "\n",
    "        x, y = np.real(trajectory), np.imag(trajectory)\n",
    "        plt.scatter(x, y, s=50, c='r')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this class, we can visualize the current orientation of the pencil on the manifold $S^1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = S1(theta=np.pi/4)\n",
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kinematics\n",
    "The kinematics that describe the evolution of the pencil's orientation on the manifold is given by the first-order differential equation\n",
    "\n",
    "\\begin{equation}\n",
    "\\dot{z} = f(z) = j \\dot{\\theta} z = j \\omega z,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta \\in \\mathfrak{g} = \\mathbb{R}$ and $z \\in \\mathcal{G} = S^1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euler's Method (Naive)\n",
    "We would like to use a computer to approximate this ODE. A common numerical method for solving first-order ODEs is Euler's Method, an explicit algorithm which uses the limit definition of a derivative to find the update rule\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{z(t+h)-z(t)}{h} &= j\\omega z(t)\\\\\n",
    "z(t+T_s) &= z(t)+h\\omega j z(t).\n",
    "\\end{align}\n",
    "\n",
    "Assuming $\\omega$ is constant in each sample interval and using $h=T_s$ (since that's when we have data to integrate), discretizing yields the digital algorithm\n",
    "\n",
    "\\begin{align}\n",
    "z[n+1] &= z[n]+jT_s\\omega[n] z[n]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1(S1):\n",
    "    def euler_integration(self, w, Ts=0.01, secs=5, **kwargs):\n",
    "        # convert seconds to steps\n",
    "        steps = int(secs/Ts)\n",
    "        \n",
    "        # Store trajectory\n",
    "        trajectory = np.zeros((steps+1,), dtype=complex)\n",
    "        trajectory[0] = self.z\n",
    "\n",
    "        for i in range(steps):\n",
    "            self.z += Ts*( 1j*w[i]*self.z )\n",
    "            trajectory[i+1] = self.z\n",
    "            \n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = S1(theta=np.pi/4)\n",
    "traj = z.euler_integration(w, **P)\n",
    "print(\"|z_final| = {:.4f}\".format(np.abs(traj[-1])))\n",
    "z.visualize(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this approach is that Euler's Method as it was implemented is only for Euclidean spaces. Note that the update steps calls for the addition of two group elements, which is not defined in $S^1$ and this scheme will cause the updated group element to lose the group property that $|z|=1$ and thus it will leave the manifold.\n",
    "\n",
    "This is the core motivation for a study of Lie groups. Without the Lie group machinery, our estimation and control algorithms would suffer from numerical instability or costly normalization steps to reproject the updated value onto the manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runge-Kutta 4 (RK4)\n",
    "Of course, Euler's Method is a first-order, rough approximation of any differential equation -- even in Euclidean space. We can build a much stronger argument for the need of Lie group integrators by investigating the results of integrating the differential equation using the Euclidean RK4 method. The RK4 method is given by\n",
    "\n",
    "\\begin{align}\n",
    "y_{n+1}\t&=\ty_{n}+\\frac{h}{6}\\left(k_{1}+2k_{2}+2k_{3}+k4\\right) \\\\\n",
    "t_{n+1}\t&=\tt_{n}+h\n",
    " \\end{align}\n",
    " \n",
    "where\n",
    " \n",
    "\\begin{align}\n",
    "k_{1} &= f\\left(t_{n},y_{n}\\right) \\\\\n",
    "k_{2} &= f\\left(t_{n}+\\frac{h}{2},y_{n}+\\frac{h}{2}k_{1}\\right) \\\\\n",
    "k_{3} &= f\\left(t_{n}+\\frac{h}{2},y_{n}+\\frac{h}{2}k_{2}\\right) \\\\\n",
    "k_{4} &= f\\left(t_{n}+h,y_{n}+hk_{3}\\right)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1(S1):\n",
    "    def rk4_integration(self, w, Ts=0.01, secs=5, **kwargs):\n",
    "        # convert seconds to steps\n",
    "        steps = int(secs/Ts)\n",
    "        \n",
    "        # Store trajectory\n",
    "        trajectory = np.zeros((steps+1,), dtype=complex)\n",
    "        trajectory[0] = self.z\n",
    "        \n",
    "        f = lambda i, t, z: 1j*w[i]*z\n",
    "\n",
    "        for i in range(steps):\n",
    "            t = i*Ts\n",
    "            k1 = f(i, t, self.z)\n",
    "            k2 = f(i, t + Ts/2, self.z + Ts/2*k1)\n",
    "            k3 = f(i, t + Ts/2, self.z + Ts/2*k2)\n",
    "            k4 = f(i, t + Ts  , self.z + Ts  *k3)\n",
    "            self.z += (Ts/6)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "            trajectory[i+1] = self.z\n",
    "\n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = S1(theta=np.pi/4)\n",
    "traj = z.rk4_integration(w, **P)\n",
    "print(\"|z_final| = {:.4f}\".format(np.abs(traj[-2])))\n",
    "z.visualize(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RK4 numerical integration does much better! But again, we can see that it breaks the constraint that $|z|=1$ and the updated elements eventually start leaving the manifold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Lie Integrator\n",
    "Instead of using classic numerical techniques to approximate the solution to the $S^1$ kinematic equation, instead we can analytically solve the ODE and then discretize to obtain a digital implementation. This makes us feel better since it is rooted in mathematical theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that the kinematics\n",
    "\n",
    "\\begin{equation}\n",
    "\\dot{z} = f(z) = j \\omega z,\n",
    "\\end{equation}\n",
    "\n",
    "is of the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dz}{dt} + p(t)z(t) = q(t)\n",
    "\\end{equation}\n",
    "\n",
    "with $p(t)=-j \\omega$ and $q(t) = 0$, we can use the integrating factor  $exp(-\\int_{t_{0}}^{t}j\\theta\\left(\\tau\\right)d\\tau)$ to find a solution that satisfies this differential equation.\n",
    "\n",
    "Making no assumptions about the content of the continuous signal $\\omega(t)$, and using the integrating factor, we can write the kinematics as\n",
    "\n",
    "\\begin{equation}\n",
    "\\left(\\dot{z}-j\\omega(t)z\\right)e^{-\\int_{t_{0}}^{t}j\\omega\\left(\\tau\\right)d\\tau} = 0.\n",
    "\\end{equation}\n",
    "\n",
    "Using the product rule, this becomes\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d}{dt}\\left[ze^{-\\int_{t_{0}}^{t}j\\omega\\left(\\tau\\right)d\\tau}\\right]=0.\n",
    "\\end{equation}\n",
    "\n",
    "Taking the integral of both sides with respect to time gives\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{t_{0}}^{t}\\frac{d}{d\\tau}\\left[ze^{-\\int_{t_{0}}^{\\tau}j\\omega\\left(\\sigma\\right)d\\sigma}\\right]d\\tau=0,\n",
    "\\end{equation}\n",
    "\n",
    "for which we can use the Fundamental Theorem of Calculus to find the solution\n",
    "\n",
    "\\begin{align}\n",
    "z(t)e^{-\\int_{t_{0}}^{t}j\\omega\\left(\\tau\\right)d\\tau}-z(t_{0})e^{-\\int_{t_{0}}^{t_{0}}j\\omega\\left(\\tau\\right)d\\tau}\t&=\t0 \\\\\n",
    "z(t)\t&=\tz(t_{0})e^{\\int_{t_{0}}^{t}j\\omega(\\tau)d\\tau}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Digital Implementation: Zero-Order Hold\n",
    "Because the gyro gives discrete samples every $T_s$ seconds, we need to discretize the solution for digital implementation. Let $t=nT_s$, $t_0=(n-1)T_s$ and use the notation $z[n]=z(nT_s)$. By using the concept of ZOH sampling, we assume that the signal is constant during the sample interval with $\\omega[n]$. Therefore, $\\int_{t_{0}}^{t}j\\omega\\left(\\tau\\right)d\\tau=j\\omega[n]T_{s}$ and\n",
    "\n",
    "\\begin{equation}\n",
    "z[n]=z[n-1]e^{j\\omega[n]T_{s}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S1(S1):\n",
    "    def lie_integration_zoh(self, w, Ts, secs=0, **kwargs):\n",
    "        # convert seconds to steps\n",
    "        steps = int(secs/Ts)\n",
    "        \n",
    "        # Store trajectory\n",
    "        trajectory = np.zeros((steps+1,), dtype=complex)\n",
    "        trajectory[0] = self.z\n",
    "        \n",
    "        for i in range(steps):\n",
    "            self.z = self.z*np.exp(1j*w[i]*Ts)\n",
    "            trajectory[i+1] = self.z\n",
    "            \n",
    "        return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = S1(theta=np.pi/4)\n",
    "traj = z.lie_integration_zoh(w, **P)\n",
    "print(\"|z_final| = {:.4f}\".format(np.abs(traj[-1])))\n",
    "z.visualize(traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the exponential mapping at each update, we see that the updated element stays on the manifold and maintains the geometric constraint $|z|=1$. Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Digital Implementation: Delayed First-Order Hold\n",
    "To increase our accuracy (especially for slower sampling rates), we assume that the signal is changing linearly between samples and apply a FOH. Note that for this scheme to implemented causally, it introduces a one sample lag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control\n",
    "\n",
    "We'll use as an example the azimuth control of a directional high-gain tracking antenna. The system state consists of the antenna direction $\\Phi \\in SO(2)$, and the angular velocity $\\omega \\in \\mathbb{R}$. The input to the system is the torque $\\tau$. The system dynamics are given by\n",
    "\\begin{eqnarray}\n",
    "\\dot{\\Phi} &= \\Phi \\omega^\\wedge \\nonumber\\\\\n",
    "\\dot{\\omega} &= -\\frac{b}{I} \\omega + \\frac{1}{I} \\tau \\;,\n",
    "\\label{eq:dynamics}\n",
    "\\end{eqnarray}\n",
    "where $I>0$ is the inertia and $b>0$ is a damping term. Following the discussion on solving differential equations, we will discretize these dynamics for computer simulation as\n",
    "\\begin{align}\n",
    "\\omega[k] &= \\omega[k-1] + \\left(-\\frac{b}{I} \\omega[k-1] + \\frac{1}{I}\\tau[k] \\right) T_s \\\\\n",
    "\\Phi[k] &= \\Phi[k-1] \\circ \\exp\\left(\\left(\\omega[k] T_s\\right)^\\wedge\\right)\n",
    "\\end{align}\n",
    "\n",
    "We will use the native representation for elements of $SO(2)$ as $2\\times2$ rotation matrices for our representation of the antenna orientation. This is implemented in the following Python class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class SO2:\n",
    "    def __init__(self, G=np.eye(2)):\n",
    "        self.mat = G\n",
    "\n",
    "    def dot(self, rhs):\n",
    "        return SO2(np.dot(self.mat, rhs.mat))\n",
    "\n",
    "    @staticmethod\n",
    "    def identity():\n",
    "        return SO2(np.eye(2))\n",
    "\n",
    "    def inverse(self):\n",
    "        return SO2(self.mat.T)\n",
    "\n",
    "    @staticmethod\n",
    "    def exp(g):\n",
    "        omega = SO2.vee(g)\n",
    "        return SO2(np.array([[np.cos(omega), -np.sin(omega)], [np.sin(omega), np.cos(omega)]]))\n",
    "\n",
    "    def log(self):\n",
    "        theta = self.to_angle()\n",
    "        return np.array([[0, -theta], [theta, 0]])\n",
    "\n",
    "    @staticmethod\n",
    "    def hat(omega):\n",
    "        return np.array([[0.0, -omega],[omega, 0.0]])\n",
    "\n",
    "    @staticmethod\n",
    "    def vee(g):\n",
    "        return g[1,0]\n",
    "\n",
    "    def to_angle(self):\n",
    "        return np.arctan2(self.mat[1,0], self.mat[0,0])\n",
    "\n",
    "    @staticmethod\n",
    "    def from_angle(theta):\n",
    "        return SO2.exp(SO2.hat(theta))\n",
    "\n",
    "    def visualize(self):\n",
    "        pos = self.mat.dot(np.array([1.0, 0]))\n",
    "        return pos[0], pos[1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.mat.__str__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.mat.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set up our simulator to be able to accept a variety of controllers, which we will explore in the next sections. The simulator is implemented by the following class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, controller, commands=[0.0], command_duration=5.0):\n",
    "        self.controller = controller\n",
    "\n",
    "        # time\n",
    "        self.dt = 0.01\n",
    "        self.t = np.arange(0.0, command_duration*len(commands), self.dt)\n",
    "\n",
    "        # system parameters\n",
    "        self.I = 1.0\n",
    "        self.b = 0.1\n",
    "\n",
    "        # system state\n",
    "        self.Phi = SO2()\n",
    "        self.omega = 0.0\n",
    "\n",
    "        # commands\n",
    "        self.theta_c = np.zeros(self.t.shape)\n",
    "        for i in range(len(commands)):\n",
    "            self.theta_c[i*self.t.size//len(commands):(i+1)*self.t.size//len(commands)] = commands[i]\n",
    "\n",
    "        # history\n",
    "        self.theta_hist = np.zeros(self.t.shape)\n",
    "        self.omega_hist = np.zeros(self.t.shape)\n",
    "        self.tau_hist = np.zeros(self.t.shape)\n",
    "\n",
    "    def animate(self):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, aspect='equal', xlim=[-1.2, 1.2], ylim=[-1.2,1.2])\n",
    "        ax.axis('off')\n",
    "        ax.set_title(self.controller.name)\n",
    "\n",
    "        th = np.linspace(0, 2*np.pi, 100)\n",
    "        ax.plot(np.cos(th), np.sin(th), 'k-')\n",
    "\n",
    "        self.command_line = ax.plot([], [], 'ro', label='command')[0]\n",
    "        self.actual_line = ax.plot([], [], 'bo', label='actual')[0]\n",
    "        ax.legend(loc='center', numpoints=1)\n",
    "\n",
    "        return animation.FuncAnimation(fig, self.step, frames=len(self.t), interval=int(1000*self.dt), blit=False, repeat=False)\n",
    "\n",
    "    def step(self, k):\n",
    "        # if the controller uses a manifold representation, convert the command to an element of SO(2)\n",
    "        if self.controller.manifold:\n",
    "            tau = self.controller.run(SO2.from_angle(self.theta_c[k]), self.Phi, self.omega)\n",
    "        else:\n",
    "            tau = self.controller.run(self.theta_c[k], self.Phi.to_angle(), self.omega)\n",
    "\n",
    "        # propagate dynamics\n",
    "        self.omega += (-self.b/self.I*self.omega + 1.0/self.I*tau)*self.dt\n",
    "        self.Phi = self.Phi.dot(SO2.exp(SO2.hat(self.omega*self.dt)))\n",
    "\n",
    "        # store history\n",
    "        self.theta_hist[k] = self.Phi.to_angle()\n",
    "        self.omega_hist[k] = self.omega\n",
    "        self.tau_hist[k] = tau\n",
    "\n",
    "        x_c, y_c = SO2.exp(SO2.hat(self.theta_c[k])).visualize()\n",
    "        x, y = self.Phi.visualize()\n",
    "\n",
    "        self.command_line.set_data(x_c, y_c)\n",
    "        self.actual_line.set_data(x, y)\n",
    "\n",
    "    def plot(self):\n",
    "        plt.ioff()\n",
    "        fig = plt.figure()\n",
    "\n",
    "        ax = fig.add_subplot(311)\n",
    "        ax.plot(self.t, self.theta_c, 'r-', label='command')\n",
    "        ax.plot(self.t, self.theta_hist, 'b-', label='actual')\n",
    "        ax.set_title(self.controller.name)\n",
    "        ax.set_ylabel('theta (rad)')\n",
    "        ax.legend()\n",
    "\n",
    "        ax = fig.add_subplot(312)\n",
    "        ax.plot(self.t, self.omega_hist, 'b-')\n",
    "        ax.set_ylabel('omega (rad/s)')\n",
    "\n",
    "        ax = fig.add_subplot(313)\n",
    "        ax.plot(self.t, self.tau_hist, 'm-')\n",
    "        ax.set_xlabel('time (s)')\n",
    "        ax.set_ylabel('torque (N*m)')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive PID Control\n",
    "\n",
    "We will begin by designing a simple PID controller following a more traditional approach without using a manifold representation for the orientation. Representing the orientation of the antenna by the angle $\\theta \\in \\left(-\\pi,\\pi \\right]$, we can write the equation of motion as\n",
    "\\begin{equation}\n",
    "I \\ddot{\\theta} + b \\dot{\\theta} = \\tau \\;,\n",
    "\\end{equation}\n",
    "from which we obtain the transfer function\n",
    "\\begin{equation}\n",
    "\\Theta(s) = \\frac{1}{s\\left( Is + b \\right)} T(s) \\;.\n",
    "\\end{equation}\n",
    "For a simple PD controller the control law is given by\n",
    "\\begin{equation}\n",
    "\\tau = k_p \\left(\\theta^c - \\theta\\right) - k_d \\omega \\;,\n",
    "\\end{equation}\n",
    "where $\\theta^c$ is the commanded orientation. This yields the closed-loop transfer function\n",
    "\\begin{equation}\n",
    "\\Theta(s) = \\frac{k_p}{I s^2 + (b + k_d)s + k_p} \\Theta^c (s) \\;,\n",
    "\\end{equation}\n",
    "from which we can see that the system will be stable as long as $k_p>0$ and $b+k_d>0$, and that there will be zero steady-state error to a step input.\n",
    "\n",
    "Choosing appropriate gains $k_p$ and $k_d$, we will simulate the response of this controller to step inputs as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PID_Naive:\n",
    "    def __init__(self, kp, kd):\n",
    "        self.name = \"Naive PID\"\n",
    "        self.manifold = False\n",
    "\n",
    "        self.kp = kp\n",
    "        self.kd = kd\n",
    "\n",
    "    def run(self, theta_c, theta, omega):\n",
    "        return self.kp*(theta_c - theta) - self.kd*omega\n",
    "\n",
    "sim = Simulator(PID_Naive(kp=2.0, kd=1.8), commands=[3*np.pi/4, -3*np.pi/4])\n",
    "HTML(sim.animate().to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The controller appears to perform well under these conditions. However, note that when the commanded angle changes from $3\\pi/4$ to $-3\\pi/4$, the controller spins all the way around the circle clockwise the long way, instead of taking the shortest path counter-clockwise. This happens because we are representing the orientation as angles in the range $(-\\pi,\\pi]$, and this representation contains no information about the relationship between angles near the boundaries of this range.\n",
    "\n",
    "In the example above this behavior might be annoying, but if not accounted for it can actually destabilize the system because if it overshoots and crosses the $-\\pi$ or $\\pi$ boundaries it doesn't know to back up and instead tries to go all the way around the circle again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator(PID_Naive(kp=2.0, kd=0.4), commands=[3*np.pi/4], command_duration=10.0)\n",
    "HTML(sim.animate().to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if we were not careful about how we define our commanded angles, we can also get into trouble. For example, if we command we an angle greater than $2\\pi$, the controller will want to go all the way around the circle once before settling on the desired orientation, but since the angle only goes up to $\\pi$ it will never arrive there and will go unstable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator(PID_Naive(kp=2.0, kd=1.8), commands=[2*np.pi + np.pi/4])\n",
    "HTML(sim.animate().to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the case of $SO(2)$, all of these problems can be solved by adding in additional logic to carefully account for the angle-wrapping issues introduced by representing orientation as a scalar in the range $(-\\pi,\\pi]$. However, when we get to orientations in $SO(3)$ for three dimensions, that option will no longer be viable since orientation representations (such as Euler angles, quaternions, etc.) become much less trivial.\n",
    "\n",
    "Additionally, these issue arise fundamentally because we are representing orientation as a member of a vector space, when in fact it is not. As will be shown in the next section, these issues disappear when representing the angle as a member of a Lie group, because all of the information that goes into the angle-wrapping logic is already captured by the group structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold PID control\n",
    "\n",
    "For a PID controller on the manifold, we can no longer write the error using subtraction because the manifold is not a vector space. Instead, the error is a member of the Lie algebra $\\mathfrak{so}(2)$, and is computed using the logarithmic mapping as\n",
    "\\begin{equation}\n",
    "e = \\log\\left( \\Phi^c \\circ \\Phi^{-1} \\right)^\\vee \\;.\n",
    "\\end{equation}\n",
    "We then write our control law as\n",
    "\\begin{equation} \\label{eq:tau_1}\n",
    "\\tau = k_p e - k_d \\omega \\;.\n",
    "\\end{equation}\n",
    "\n",
    "This is simulated as follows using the same gains and step inputs as for the naive PD controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PID_Manifold:\n",
    "    def __init__(self, kp, kd):\n",
    "        self.name = \"Manifold PID\"\n",
    "        self.manifold = True\n",
    "\n",
    "        self.kp = kp\n",
    "        self.kd = kd\n",
    "\n",
    "    def run(self, theta_c, theta, omega):\n",
    "        return self.kp*SO2.vee(theta_c.dot(theta.inverse()).log()) - self.kd*omega\n",
    "\n",
    "sim = Simulator(PID_Manifold(kp=2.0, kd=1.8), commands=[3*np.pi/4, -3*np.pi/4])\n",
    "HTML(sim.animate().to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the results, converting the orientation to a scalar angle representation for the sake of visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the controller properly takes the shortest path around the circle, because it utilizes the information about relationships between angles encoded in the group structure. This looks slightly strange in the plots above as if it starts going the wrong direction, but that is a limitation of the visualization and is in fact the correct behavior.\n",
    "\n",
    "Because the group structure properly accounts for the relationships between angles, we no longer have the stability issues caused by overshoot that we saw with the naive approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator(PID_Manifold(kp=2.0, kd=0.4), commands=[3*np.pi/4], command_duration=10.0)\n",
    "HTML(sim.animate().to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, by also encoding the commanded angles as members of $SO(2)$, we avoid issues with commanded angles that are outside of the range $(-\\pi,\\pi]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator(PID_Manifold(kp=2.0, kd=1.8), commands=[2*np.pi + np.pi/4])\n",
    "HTML(sim.animate().to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this result looks strange in the plots, but this is because the plots do not encode the group structure that is accounted for in the controller and the result is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis\n",
    "\n",
    "In this section we show Lyapnov functions and make convergence arguments for proportional and proportional-derivative control.  \n",
    "\n",
    "### Lyapunov Refresher\n",
    "To set the stage, suppose that we have a first order kinematic equation $\\dot{z}=z+u$ where $z$ is the state and $u$ is the control variable.  Suppose that the objective is for $z$ to follow $z_d$.  Define the Lyapunov function\n",
    "$$\n",
    "V = \\frac{1}{2}\\|z_d-z\\|^2\n",
    "$$\n",
    "and take the time derivative of $V$ to get\n",
    "$$\n",
    "\\dot{V} = (z_d-z)(\\dot{z}_d-\\dot{z}) = (z_d-z)(\\dot{z}_d-z-u).\n",
    "$$\n",
    "Selecting the control as \n",
    "$$\n",
    "u=\\dot{z}_d - z + k_p(z_d-z)\n",
    "$$\n",
    "gives\n",
    "$$\n",
    "\\dot{V} = -k_p(z_d-z)^2\n",
    "$$ \n",
    "establishing the convergence of $z(t)$ to $z_d(t)$.\n",
    "\n",
    "Now consider the second order dynamics\n",
    "\\begin{align*}\n",
    "\\dot{z} &= w \\\\\n",
    "\\dot{w} &= u,\n",
    "\\end{align*}\n",
    "and again suppose that the objective is for $z$ to follow $z_d$.  Define the Lyapunov function\n",
    "$$\n",
    "V = \\frac{k_p}{2}\\|z_d-z\\|^2 + \\frac{1}{2}\\|w\\|^2,\n",
    "$$\n",
    "and take the time derivative to get\n",
    "\\begin{align*}\n",
    "\\dot{V} &= k_p (z_d-z)^\\top(\\dot{z}_d-\\dot{z}) + w^\\top \\dot{w} \\\\\n",
    "        &= -k_p (z_d-z)^\\top w + w^\\top u +  k_p (z_d-z)^\\top\\dot{z}_d \\\\\n",
    "        &= w^\\top \\left( u -k_p (z_d-z) \\right) +  k_p (z_d-z)^\\top\\dot{z}_d.\n",
    "\\end{align*}\n",
    "Selecting the control variable as\n",
    "\\begin{equation}\\label{eq:control_u}\n",
    "u = k_p(z_d-z) - k_d w\n",
    "\\end{equation}\n",
    "gives \n",
    "$$\n",
    "\\dot{V} = -k_d\\|w\\|^2 +  k_p (z_d-z)^\\top\\dot{z}_d.\n",
    "$$\n",
    "If $\\dot{z}_d=0$ then the system converges to the set $E=\\{(z, w): w=0\\}$.  The largest invariant set in $E$ is characterized by the property that $w\\equiv\\dot{w}\\equiv 0$, which from Equation \\eqref{eq:control_u} implies that $z\\equiv z_d$.   Therefore, the LaSalle invariance lemma implies that $z(t)\\to z_d$.  If $\\dot{z}_d$ is not zero, then a straightforward argument shows that the system trajectors are uniformly ultimately bounded with ultimate bound related to $\\dot{z}_d$.\n",
    "\n",
    "\n",
    "### Convergence analysis for first order kinematics\n",
    "\n",
    "Our objective is to derive a similar controller over a lie group for the first order kinematic expression\n",
    "$$\n",
    "\\dot{R}=R\\omega^\\wedge,\n",
    "$$\n",
    "where the objective is to drive $R$ to $R_d$.  Define the error $\\tilde{R}=R_d^\\top R$, and consider the Lyapunov function\n",
    "\\begin{equation} \\label{eq:Lyapunov-1}\n",
    "V = \\frac{1}{2}\\|I-\\tilde{R}\\|^2,\n",
    "\\end{equation}\n",
    "where the matrix norm is defined as \n",
    "$$\n",
    "\\|A\\| \\stackrel{\\triangle}{=} \\langle\\langle A, A \\rangle\\rangle\n",
    "$$\n",
    "and the matrix inner product is defined as\n",
    "$$\n",
    "\\langle\\langle A, B \\rangle\\rangle = tr\\left[ A^\\top B \\right],\n",
    "$$\n",
    "and $tr\\left[ \\cdot \\right]$ is the trace of the matrix.\n",
    "\n",
    "We will have need of the following properties of the trace:\n",
    "\n",
    "T.1. $tr\\left[ A^\\top \\right]=tr\\left[ A \\right]$,\n",
    "\n",
    "T.2. $tr\\left[ AB \\right] = tr\\left[ BA \\right]$,\n",
    "\n",
    "T.3. $tr\\left[ \\alpha A + \\beta B \\right] = \\alpha tr\\left[ A \\right] + \\beta tr\\left[ B \\right]$ where $\\alpha$ and $\\beta$ are scalars, \n",
    "\n",
    "T.4. $tr\\left[ AB \\right] = 0$ when $A$ is a symmetric matrix and $B$ is a skew-symmetric matrix,\n",
    "\n",
    "T.5. $tr\\left[ a^\\wedge b^\\wedge \\right] = -2a^\\top b$, where $a, b \\in \\mathbb{R}^3$.\n",
    "\n",
    "Using these properties we can rewrite equation \\eqref{eq:Lyapunov-1} as\n",
    "\\begin{align*}\n",
    "V &= \\frac{1}{2}\\|I-\\tilde{R}\\|^2 \\\\\n",
    "  &= \\frac{1}{2} tr\\left[(I-\\tilde{R})^\\top(I-\\tilde{R})\\right] \\\\\n",
    "  &= \\frac{1}{2} tr\\left[ I - \\tilde{R} - \\tilde{R}^\\top + \\tilde{R}^\\top\\tilde{R}\\right] \\\\\n",
    "  &= tr\\left[I-\\tilde{R}\\right].\n",
    "\\end{align*}\n",
    "Taking the derivative with respect to time gives\n",
    "\\begin{align}\n",
    "\\dot{V} &= -tr\\left[ \\dot{\\tilde{R}} \\right] \\notag \\\\\n",
    "        &= -tr\\left[ \\dot{R}_d^\\top R + R_d^\\top \\dot{R} \\right] \\notag\\\\\n",
    "        &= -tr\\left[ \\dot{R}_d^\\top R + R_d^\\top R \\omega^\\wedge \\right] \\notag\\\\\n",
    "        &= -tr\\left[ \\dot{R}_d^\\top R + \\tilde{R} \\omega^\\wedge \\right]. \\label{eq:lyapunov_derivative_2}\n",
    "\\end{align}\n",
    "Assume for the moment that $\\dot{R}_d=0$, then \n",
    "\\begin{equation}\\label{eq:lyapunov_derivative_1}\n",
    "\\dot{V} = -tr\\left[ \\tilde{R}\\omega^\\wedge \\right].\n",
    "\\end{equation}\n",
    "\n",
    "Define the symetric and skew symmetric operators as\n",
    "\\begin{align*}\n",
    "\\mathbb{P}_s (A) &\\stackrel{\\triangle}{=} \\frac{1}{2}(A+A^\\top) \\\\\n",
    "\\mathbb{P}_a (A) &\\stackrel{\\triangle}{=} \\frac{1}{2}(A-A^\\top),\n",
    "\\end{align*}\n",
    "and note that $A=\\mathbb{P}_s(A)+\\mathbb{P}_a(A)$.  Equation \\eqref{eq:lyapunov_derivative_1} then become\n",
    "\\begin{align*}\n",
    "\\dot{V} &= -tr\\left[ \\mathbb{P}_s(\\tilde{R})\\omega^\\wedge + \\mathbb{P}_a(\\tilde{R})\\omega^\\wedge \\right] \\\\\n",
    "        &= -tr\\left[ \\mathbb{P}_a(\\tilde{R})\\omega^\\wedge \\right],\n",
    "\\end{align*}\n",
    "where the second line follows form property T.4 above.  If the control variable $\\omega$ is selected as\n",
    "\\begin{equation}\\label{eq:omega_1}\n",
    "\\omega = k_p \\mathbb{P}^\\top_a(\\tilde{R})^\\vee,\n",
    "\\end{equation}\n",
    "then \n",
    "\\begin{align*}\n",
    "\\dot{V} &= - k_p tr\\left[ \\mathbb{P}_a(\\tilde{R})\\mathbb{P}^\\top_a(\\tilde{R}) \\right] \\\\\n",
    "        &= - k_p tr\\left[ \\mathbb{P}_a^\\top(\\tilde{R})\\mathbb{P}_a(\\tilde{R}) \\right] \\\\\n",
    "        &= - k_p \\langle\\langle \\mathbb{P}_a(\\tilde{R}), \\mathbb{P}_a(\\tilde{R}) \\rangle\\rangle \\\\\n",
    "        &= - k_p \\| \\mathbb{P}_a(\\tilde{R}) \\|^2,\n",
    "\\end{align*}\n",
    "which is negative definite in $\\tilde{R}$.  Note that since $\\mathbb{P}_a^\\top(\\tilde{R})=-\\mathbb{P}_a(\\tilde{R})$, Equation \\eqref{eq:omega_1} can be written as \n",
    "\\begin{equation}\\label{eq:omega_2}\n",
    "\\omega = -k_p \\mathbb{P}_a(\\tilde{R})^\\vee.\n",
    "\\end{equation}\n",
    "Also note that if $R=e^{\\theta u^\\wedge}$, then $\\log{R} = \\theta u^{\\wedge}$.  Also, since for $R\\in SO(3)$ we have \n",
    "$$\n",
    "R=e^{\\theta u^\\wedge} = \\cos\\theta I + \\sin\\theta u^{\\wedge} + (1-\\cos\\theta)uu^\\top\n",
    "$$\n",
    "that \n",
    "\\begin{align*}\n",
    "\\mathbb{P}_a(\\tilde{R}) &= \\frac{1}{2}\\left[\\cos\\theta I + \\sin\\theta u^{\\wedge} + (1-\\cos\\theta)uu^\\top\n",
    "-\\cos\\theta I + \\sin\\theta u^{\\wedge} - (1-\\cos\\theta)uu^\\top \\right] \\\\\n",
    "  &= \\sin\\theta u^\\wedge,\n",
    "\\end{align*}\n",
    "that Equation \\eqref{eq:omega_2} is closely related to Equation \\eqref{eq:tau_1}.\n",
    "\n",
    "Now suppose that $\\dot{R}_d \\neq 0$, and let $\\omega = -k_p\\mathbb{P}_a(\\tilde{R})^\\vee + \\Omega$ where $\\Omega$ will be a feedforward term that cancels the effect of $\\dot{R}_d$.  From Equation \\eqref{eq:lyapunov_derivative_2} we have\n",
    "$$\n",
    "\\dot{V} = -k_p\\|\\mathbb{P}_a(\\tilde{R})\\|^2 - tr\\left[ \\dot{R}_d^\\top R + \\tilde{R}\\Omega^\\wedge \\right].\n",
    "$$\n",
    "The goal is to select $\\Omega$ so that the second term is equal to zero.  Toward that end we have\n",
    "\\begin{align*}\n",
    "& tr\\left[ \\dot{R}_d^\\top R + \\tilde{R}\\Omega^\\wedge \\right] = 0 \\\\\n",
    "\\iff & -tr\\left[ \\tilde{R}\\Omega^\\wedge \\right] = tr\\left[ \\dot{R}_d^\\top R \\right] \\\\\n",
    "\\iff & -tr\\left[ \\mathbb{P}_s(\\tilde{R})\\Omega^\\wedge + \\mathbb{P}_a(\\tilde{R})\\Omega^\\wedge \\right] = tr\\left[ \\dot{R}_d^\\top R \\right] \\\\\n",
    "\\iff & -tr\\left[ \\mathbb{P}_a(\\tilde{R})\\Omega^\\wedge \\right] = tr\\left[ \\dot{R}_d^\\top R \\right] \\quad \\text{(by T.4)}\\\\\n",
    "\\iff & 2(\\mathbb{P}_a(\\tilde{R})^\\vee)^\\top \\Omega = tr\\left[ \\dot{R}_d^\\top R \\right] \\quad \\text{(by T.5)}.\n",
    "\\end{align*}\n",
    "Therefore let\n",
    "$$\n",
    "\\Omega = \\begin{cases}\n",
    "         \\frac{1}{2} tr\\left[ \\dot{R}_d^\\top R \\right] \\frac{\\mathbb{P}_a(\\tilde{R})^\\vee}{\\|\\mathbb{P}_a(\\tilde{R})^\\vee\\|^2}, & \\quad \\text{if} \\quad \\|\\mathbb{P}_a(\\tilde{R})^\\vee\\| \\neq 0 \\\\\n",
    "         0, & \\quad \\text{otherwise}\n",
    "         \\end{cases}.\n",
    "$$\n",
    "We note that $ \\|\\mathbb{P}_a(\\tilde{R})^\\vee\\|=0$ iff $\\tilde{R}=I$.  The above Lyapunov analysis guarantees that $R\\to R_d$.\n",
    "\n",
    "### Convergence analysis for second order dynamics\n",
    "\n",
    "Now consider the second order dynamics\n",
    "\\begin{align*}\n",
    "\\dot{R} &= R\\omega^\\wedge \\\\\n",
    "\\dot{\\omega} &= -\\frac{b}{I}\\omega + \\frac{1}{I}\\tau,\n",
    "\\end{align*}\n",
    "and again let $\\tilde{R}=R_d^\\top R$.\n",
    "  \n",
    "Consider the Lyapunov function candidate\n",
    "\\begin{align*}\n",
    "V &= \\frac{k_p}{4I}\\|I-\\tilde{R}\\|^2 + \\frac{1}{2}\\|\\omega\\|^2 \\\\\n",
    "  &= \\frac{k_p}{2I}tr\\left[ I-\\tilde{R} \\right] + \\frac{1}{2}\\omega^\\top \\omega.\n",
    "\\end{align*}\n",
    "Taking the time derivative of $V$ gives\n",
    "\\begin{align*}\n",
    "\\dot{V} &= -\\frac{k_p}{2I} tr\\left[ \\dot{\\tilde{R}} \\right] + \\omega^\\top \\dot{\\omega} \\\\\n",
    "        &= -\\frac{k_p}{2I} tr\\left[ \\dot{R}_d^\\top R + \\tilde{R}\\omega^\\wedge \\right] + \\omega^\\top (-\\frac{b}{I}\\omega + \\frac{1}{I}\\tau) \\\\\n",
    "        &= -\\frac{k_p}{2I} tr\\left[ \\dot{R}_d^\\top R + (\\mathbb{P}_s(\\tilde{R})+\\mathbb{P}_a(\\tilde{R}))\\omega^\\wedge \\right] + \\omega^\\top (-\\frac{b}{I}\\omega + \\frac{1}{I}\\tau) \\\\\n",
    "        &= -\\frac{k_p}{2I} tr\\left[ \\dot{R}_d^\\top R + \\mathbb{P}_a(\\tilde{R})\\omega^\\wedge \\right] + \\omega^\\top (-\\frac{b}{I}\\omega + \\frac{1}{I}\\tau) \\\\\n",
    "        &= \\frac{k_p}{I} \\mathbb{P}_a^\\top(\\tilde{R})^\\vee \\omega + \\omega^\\top (-\\frac{b}{I}\\omega + \\frac{1}{I}\\tau) -\\frac{k_p}{2I} tr\\left[ \\dot{R}_d^\\top R \\right]\\\\\n",
    "        &= \\omega^\\top \\left( \\frac{k_p}{I} \\mathbb{P}_a(\\tilde{R})^\\vee -\\frac{b}{I}\\omega + \\frac{1}{I}\\tau\\right) -\\frac{k_p}{2I} tr\\left[ \\dot{R}_d^\\top R \\right].\n",
    "\\end{align*}\n",
    "Selecting the control input as\n",
    "\\begin{equation}\\label{eq:tau_2}\n",
    "\\tau = -k_p \\mathbb{P}_a(\\tilde{R})^\\vee - k_d\\omega\n",
    "\\end{equation}\n",
    "gives\n",
    "$$\n",
    "\\dot{V} = -\\left(\\frac{b+k_d}{I}\\right)\\|\\omega\\|^2-\\frac{k_p}{2I} tr\\left[ \\dot{R}_d^\\top R \\right].\n",
    "$$\n",
    "If $\\dot{R}_d=0$ then $\\dot{V}$ is negative semi-definite and system trajectories converge to the set $E=\\{(R,\\omega)|\\omega=0\\}$.  The largest invariant set in $E$ is characterized by $\\omega(t)\\equiv\\dot{\\omega}(t)\\equiv 0$. From Equation \\eqref{eq:tau_2} that implies that in the largest invariant set in $E$, $\\tilde{R}=I$.  Therefore, by the LaSalle invariance principle $R(t) \\to R^d$.  Again, Equation \\eqref{eq:tau_2} is closely related to Equation \\eqref{eq:tau_1}.  Straightforward arguments can be used to argue that when $\\dot{R}_d\\neq 0$ that the trajectories of the system are uniformly ultimately bounded with ultimate bound depending on $\\dot{R}_d$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Control on SO(2)\n",
    "\n",
    "In this section, we will explore optimal control on $SO(2)$.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Control Introduction\n",
    "\n",
    "In general, optimal control seeks to minimize the continuous-time cost function\n",
    "$\\newcommand{\\x}{\\mathbf{x}}$\n",
    "$\\newcommand{\\u}{\\mathbf{u}}$\n",
    "$\\newcommand{\\b}{\\mathbf{b}}$\n",
    "$\\newcommand{\\h}{\\mathbf{h}}$\n",
    "$\\newcommand{\\lp}{\\left(}$\n",
    "$\\newcommand{\\rp}{\\right)}$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "J = \\h\\lp\\x(t_0), \\x(t_f)\\rp + \\int_{t_0}^{t_f} \\mathcal{L}\\lp\\x(t), \\u(t)\\rp dt\n",
    "\\label{eq:cost_function}\n",
    "\\end{eqnarray}\n",
    "\n",
    "subject to dynamic constraints\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dot{\\mathbf{x}}(t) = f\\left(\\x(t), \\u(t)\\right),\n",
    "\\label{eq:dynamic_constraints}\n",
    "\\end{eqnarray}\n",
    "\n",
    "algebraic _path constraints_\n",
    "\\begin{eqnarray}\n",
    "\\b\\lp \\x(t) \\u(t) \\rp \\leq 0,\n",
    "\\label{eq:path_constraints}\n",
    "\\end{eqnarray}\n",
    "\n",
    "and boundary conditions\n",
    "\\begin{eqnarray}\n",
    "\\h\\lp \\x(t_0), \\x(t_f) \\rp = 0\n",
    "\\label{eq:boundary_conditions}\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\x(t)$ is the state, $\\u(t)$ is the input, and $t$ is time with $t_0$ being the initial time, and $t_f$ the final time. $\\h$ is known as the _endpoint cost_ and $\\mathcal{L}$ is known as the _Lagrangian._  In many cases, $\\b$ is given an inequality constraint, and therefore may not be zeros at the optimal solution, and there are sometimes many solutions to the above problem, therefore optimal control is known to be locally minimizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Quadratic Control\n",
    "\n",
    "A special case of quadratic control is the Linear Quadratic Regulator (LQR).  In this case, the cost function \\eqref{eq:cost_function} is defined as the following infinite-horizon quadratic expression\n",
    "$\\newcommand{\\S}{\\mathbf{S}}$\n",
    "$\\newcommand{\\Q}{\\mathbf{Q}}$\n",
    "$\\newcommand{\\R}{\\mathbf{R}}$\n",
    "$\\newcommand{\\A}{\\mathbf{A}}$\n",
    "$\\newcommand{\\B}{\\mathbf{B}}$\n",
    "$\\newcommand{\\K}{\\mathbf{K}}$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "J = \\frac{1}{2} \\int_0^{\\infty}\\lp \\x^\\top (t) \\Q \\x(t) + \\u^\\top(t)\\R\\u(t) \\rp dt\n",
    "\\label{eq:LQR_cost}\n",
    "\\end{eqnarray}\n",
    "\n",
    "subject to the linear, time-invariant first-order dynamic constraints\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dot{\\x}(t) = \\A\\x(t) + \\B\\u(t),\n",
    "\\end{eqnarray}\n",
    "\n",
    "and the initial condition\n",
    "\\begin{eqnarray}\n",
    "\\x(t_0) = \\x_0\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\x(\\infty) = 0$.\n",
    "\n",
    "It has been shown that this problem can be solved with \n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\u(t) = -\\K(t)\\x(t)\n",
    "\\end{eqnarray}\n",
    "\n",
    "where\n",
    "\\begin{eqnarray}\n",
    "\\K(t) = \\R^{-1}\\B^\\top\\S(t),\n",
    "\\end{eqnarray}\n",
    "\n",
    "and $\\S(t)$ is the solution to the algebraic Riccati equation (ARE) given as\n",
    "\\begin{eqnarray}\n",
    "0 = -\\S\\A - \\A^\\top \\S + \\S\\B\\R^{-1}\\B^\\top\\S-\\Q\n",
    "\\end{eqnarray}\n",
    "\n",
    "and can be solved for efficiently using modern scientific compution libraries such as `scipy`.  As a side node, the LQR problem was originally solved by Rudolf Kalman [(_Kalman, 1960_)](https://www.cs.unc.edu/~welch/kalman/media/pdf/Kalman1960.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LQR on SO(2)\n",
    "$\\newcommand{\\xr}{\\x^c}$\n",
    "$\\newcommand{\\xt}{\\tilde{\\x}}$\n",
    "$\\newcommand{\\ur}{\\u^c}$\n",
    "$\\newcommand{\\ut}{\\tilde{\\u}}$\n",
    "\n",
    "As it is formulated, LQR assumes that the state $\\x$ is a vector, and therefore is not natively adapted to work on the $SO(2)$ manifold.  As such, we must perform control on the _error space_ between some reference trajectory and our current state.  \n",
    "\n",
    "#### Error State Defintion\n",
    "\n",
    "As before, our state $\\x$ is defined as the tuple of the system's current position along the unit circle, expressed as a member of $SO(2)$ and the angular rate $\\omega$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\x = \\begin{pmatrix} \\Phi & \\omega \\end{pmatrix}^\\top \\;,\n",
    "\\end{eqnarray}\n",
    "\n",
    "the input $\\u$ is defined as the applied torque to the system $\\tau$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\u = \\tau \\;.\n",
    "\\end{eqnarray}\n",
    "\n",
    "The dynamics of the system are the same as before:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\dot{\\Phi} &= \\Phi \\omega^\\wedge \\\\\n",
    "\\dot{\\omega} &= -\\frac{b}{I} \\omega + \\frac{1}{I} \\tau \\;.\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "Let us define the error state, $\\xt$ between our current state $\\x$ and desired state $\\xr$ as follows:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\begin{pmatrix} \\tilde{\\Phi} \\\\ \\tilde{\\omega} \\end{pmatrix} &= \\begin{pmatrix} \\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp^\\vee \\\\ \\omega - \\omega^c \\end{pmatrix} \\\\\n",
    "    \\xt &= \\x \\boxminus \\xr \\;,\n",
    "\\end{aligned}\n",
    "\n",
    "where the $\\boxminus$ operator is defined to encapsulate the notion of \"differencing\" our desired and current state.  Similarly to when we calculated error $e$ in the definition of PID control, $\\tilde{\\Phi}\\in\\mathfrak{so}^\\vee\\cong \\mathbb{R}^1$, which means that $\\xt\\in\\mathbb{R}^2$.\n",
    "\n",
    "We also must define our error state input, which is trivially defined as\n",
    "\\begin{aligned}\n",
    "\\ut = \\u - \\ur \\;.\n",
    "\\end{aligned}\n",
    "\n",
    "#### Error State Dynamics\n",
    "\n",
    "Since we are performing LQR on the error state directly, we must find an expression for the error state dynamics.  Let's start with the definition of the error state:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\begin{pmatrix} \\tilde{\\Phi} \\\\ \\tilde{\\omega} \\end{pmatrix} &= \\begin{pmatrix} \\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp^\\vee \\\\ \\omega - \\omega^c \\end{pmatrix}\n",
    "\\end{aligned}\n",
    "\n",
    "Taking the time derivative of both side leads to\n",
    "$\\newcommand{ddt}{\\frac{d}{dt}}$\n",
    "$\\newcommand{ddP}{\\frac{d}{d\\Phi}}$\n",
    "$\\newcommand{ddPc}{\\frac{d}{d\\Phi^c}}$\n",
    "$\\newcommand{atan}{\\textrm{atan}}$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{pmatrix} \\dot{\\tilde{\\Phi}} \n",
    "        \\\\ \\dot{\\tilde{\\omega}} \\end{pmatrix} \n",
    "    &=& \\begin{pmatrix} \\ddt\\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp^\\vee \n",
    "        \\\\ \\dot{\\omega} - \\dot{\\omega}^c \\end{pmatrix}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Since the $\\omega$ term, is trivial, let us just focus on the $\\Phi$ term, using the chain rule,\n",
    "\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dot{\\tilde{\\Phi}} &=& \\ddt\\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp^\\vee \\\\\n",
    "&=& \\frac{d}{d\\lp \\Phi^c \\circ \\Phi^{-1} \\rp}(\\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp \\frac{d}{dt}\\lp \\Phi^c \\circ \\Phi^{-1} \\rp^\\vee \\\\\n",
    "&=& \\frac{d}{d\\lp \\Phi^c \\circ \\Phi^{-1} \\rp}(\\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp \\lp \\ddP\\lp \\Phi^c \\circ \\Phi^{-1} \\rp\\dot{\\Phi} + \\ddPc\\lp \\Phi^c \\circ \\Phi^{-1} \\rp\\dot{\\Phi}^c \\rp^\\vee\n",
    "\\label{eq:log_chain_rule}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three partials we need to solve \\eqref{eq:log_chain_rule}.  The first is the partial derivative of the logarithmic map.  To solve this, we will need the following expressions:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\epsilon^\\wedge \\Phi = \\epsilon \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}\\Phi \\\\\n",
    "\\lp \\epsilon^\\wedge \\Phi \\rp_{11} = \\epsilon \\Phi_{21} \\\\\n",
    "\\lp \\epsilon^\\wedge \\Phi \\rp_{21} = -\\epsilon \\Phi_{11} \\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "$\\newcommand{v}{\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}}$\n",
    "$\\newcommand{vT}{\\begin{bmatrix} 1 & 0 \\end{bmatrix}}$\n",
    "$\\newcommand{n}{\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}}$\n",
    "$\\newcommand{nT}{\\begin{bmatrix} 0 & 1 \\end{bmatrix}}$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\ddP \\log{\\Phi}^\\vee &=& \\ddP \\atan\\lp \\frac{\\Phi_{21}}{\\Phi_{11}}\\rp \\\\\n",
    "&=& \\ddP \\atan\\lp\\frac{\\Phi_{21}}{\\Phi_{11}}\\rp \\\\\n",
    "&=& \\frac{1}{1+\\lp\\frac{\\Phi_{21}}{\\Phi_{11}}\\rp^2} \\ddP\\lp\\frac{\\Phi_{21}}{\\Phi_{11}}\\rp \\\\\n",
    "&=& \\frac{1}{\\frac{\\Phi_{11}^2}{\\Phi_{11}^2}+\\lp\\frac{\\Phi_{21}}{\\Phi_{11}}\\rp^2} \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\lp\\exp(\\epsilon)\\Phi\\rp_{21}}\n",
    "{\\lp\\exp(\\epsilon)\\Phi\\rp_{11}} \n",
    "- \\frac\n",
    "{\\Phi_{21}}\n",
    "{\\Phi_{11}}\n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\frac{1}{\\frac{\\Phi_{11}^2 + \\Phi_{21}^2}{\\Phi_{11}^2}} \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\lp\\lp I + \\epsilon^\\wedge\\rp\\Phi\\rp_{21}}\n",
    "{\\lp\\lp I + \\epsilon^\\wedge\\rp\\Phi\\rp_{11}} \n",
    "- \\frac\n",
    "{\\Phi_{21}}\n",
    "{\\Phi_{11}}\n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\frac{1}{\\frac{1}{\\Phi_{11}^2}} \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\lp \\Phi + \\epsilon^\\wedge\\Phi\\rp_{21}}\n",
    "{\\lp \\Phi + \\epsilon^\\wedge\\Phi\\rp_{11}} \n",
    "- \\frac\n",
    "{\\Phi_{21}}\n",
    "{\\Phi_{11}}\n",
    "\\rp\\nonumber \\\\\n",
    "&=& \\Phi_{11}^2 \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\Phi_{21} + \\lp\\epsilon^\\wedge\\Phi\\rp_{21}}\n",
    "{\\Phi_{11} + \\lp\\epsilon^\\wedge\\Phi\\rp_{11}} \n",
    "- \\frac\n",
    "{\\Phi_{21}}\n",
    "{\\Phi_{11}}\n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\Phi_{11}^2 \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\Phi_{21} - \\epsilon \\Phi_{11}}\n",
    "{\\Phi_{11} + \\epsilon \\Phi_{21}} \n",
    "- \\frac\n",
    "{\\Phi_{21}}\n",
    "{\\Phi_{11}}\n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\Phi_{11}^2 \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\Phi_{11}\\lp\\Phi_{21} - \\epsilon \\Phi_{11}\\rp - \\Phi_{21}\\lp\\Phi_{11} - \\epsilon \\Phi_{21}\\rp}\n",
    "{\\Phi_{11}\\lp\\Phi_{11} + \\epsilon \\Phi_{21}\\rp} \n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\Phi_{11}^2 \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{\\Phi_{11}\\Phi_{21} - \\epsilon \\Phi_{11}\\Phi_{11} - \\Phi_{21}\\Phi_{11} - \\epsilon \\Phi_{21}\\Phi_{21}}\n",
    "{\\Phi_{11}\\Phi_{11} + \\epsilon \\Phi_{11}\\Phi_{21}} \n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\Phi_{11}^2 \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\n",
    "\\frac\n",
    "{-\\epsilon \\lp\\Phi_{11}^2 + \\Phi_{21}^2\\rp}\n",
    "{\\Phi_{11}^2 - \\epsilon \\Phi_{11}\\Phi_{21}} \n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\Phi_{11}^2 \\lim_{\\epsilon \\to 0}\n",
    "\\lp\n",
    "\\frac\n",
    "{-1}\n",
    "{\\Phi_{11}^2 - \\epsilon \\Phi_{11}\\Phi_{21}} \n",
    "\\rp \\nonumber\\\\\n",
    "&=& \\Phi_{11}^2\n",
    "\\lp\n",
    "\\frac\n",
    "{1}\n",
    "{\\Phi_{11}^2} \n",
    "\\rp \\nonumber\\\\\n",
    "&=& -1\n",
    "\\label{eq:log_map_jacobian}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Jacobian is Correct\n"
     ]
    }
   ],
   "source": [
    "# Check Analytical Jacobian of Logarithmic Map\n",
    "\n",
    "epsilon = 1e-8\n",
    "analytical = -1\n",
    "\n",
    "for i in range(100):\n",
    "    Phi = SO2.exp(SO2.hat(np.random.random()))\n",
    "    x0 = Phi.log()[0,1]\n",
    "    xi = SO2.exp(SO2.hat(epsilon)).dot(Phi).log()[0,1]\n",
    "    finite_difference = (xi - x0)/epsilon\n",
    "    assert abs(analytical - finite_difference) < 1e-6, \"Analytical Jacobian Doesn't Match Numerical\"\n",
    "print \"Analytical Jacobian is Correct\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must find the partial derivative of the $\\circ$ group operator on $SO(2)$ also using a limit.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\ddPc \\Phi^c \\circ \\Phi^{-1} &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\exp\\lp\\epsilon^\\wedge\\rp\\Phi^c \\Phi^{-1} \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    " &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\lp I + \\epsilon^\\wedge\\rp\\Phi^c \\Phi^{-1} \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    " &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\lp \\Phi^c + \\epsilon^\\wedge\\Phi^c\\rp \\Phi^{-1} \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    "  &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\Phi^c\\Phi^{-1} + \\epsilon^\\wedge\\Phi^c\\Phi^{-1}  \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    "    &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\epsilon^\\wedge\\Phi^c\\Phi^{-1}\\nonumber\\\\\n",
    "    &=& \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\Phi^{c}\\Phi^{-1} \\label{eq:ddPc}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Let's perform a little finite-differencing to check the analytical derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Jacobian is Correct\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-8\n",
    "\n",
    "for i in range(100):\n",
    "    Phi = SO2.exp(SO2.hat(np.random.random()))\n",
    "    Phic = SO2.exp(SO2.hat(np.random.random()))\n",
    "    analytical = np.array([[0, -1], [1, 0]]).dot(Phic.mat).dot(Phi.inverse().mat)\n",
    "    x0 = (Phic.dot(Phi.inverse())).mat\n",
    "    xi = (SO2.exp(SO2.hat(epsilon)).dot(Phic).dot(Phi.inverse())).mat\n",
    "    finite_difference = (xi - x0)/epsilon\n",
    "    assert np.sum(np.abs(analytical - finite_difference)) < 1e-6, \"Analytical Jacobian Doesn't Match Numerical\"\n",
    "print \"Analytical Jacobian is Correct\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "\\ddP \\Phi^c \\circ \\Phi^{-1} &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\Phi^c \\lp\\exp\\lp\\epsilon^\\wedge\\rp\\Phi\\rp^{-1} \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\Phi^c \\lp\\lp I + \\epsilon^\\wedge\\rp\\Phi\\rp^{-1} \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\Phi^c \\lp\\Phi^{-1} - \\Phi^{-1}\\epsilon^\\wedge\\rp \\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp \\Phi^c\\Phi^{-1} - \\Phi^c\\Phi^{-1}\\epsilon^\\wedge\\rp - \\lp\\Phi^c \\Phi^{-1} \\rp \\nonumber\\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \\lp - \\Phi^c\\Phi^{-1}\\epsilon^\\wedge\\rp \\nonumber\\\\\n",
    "&=& - \\Phi^c\\Phi^{-1} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\label{eq:ddP}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-8\n",
    "\n",
    "for i in range(100):\n",
    "    Phi = SO2.exp(SO2.hat(np.random.random()))\n",
    "    Phic = SO2.exp(SO2.hat(np.random.random()))\n",
    "    analytical = -Phic.dot(Phi.inverse()).mat.dot(np.array([[0, -1], [1, 0]]))\n",
    "    x0 = (Phic.dot(Phi.inverse())).mat\n",
    "    xi = (Phic.dot(SO2.exp(SO2.hat(epsilon)).dot(Phi).inverse())).mat\n",
    "    finite_difference = (xi - x0)/epsilon\n",
    "    assert np.sum(np.abs(analytical - finite_difference)) < 1e-6, \"Analytical Jacobian Doesn't Match Numerical\"\n",
    "print \"Analytical Jacobian is Correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we can use \\eqref{eq:ddPc} and \\eqref{eq:ddP} to solve \\eqref{eq:log_chain_rule}.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dot{\\tilde{\\Phi}}\n",
    "&=& \\lp\\frac{d}{d\\lp \\Phi^c \\circ \\Phi^{-1} \\rp}(\\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp \\lp \\ddP\\lp \\Phi^c \\circ \\Phi^{-1} \\rp\\dot{\\Phi} + \\ddPc\\lp \\Phi^c \\circ \\Phi^{-1} \\rp\\dot{\\Phi}^c \\rp\\rp^\\vee \\\\\n",
    "&=& -\\lp - \\Phi^c\\Phi^{-1} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\dot{\\Phi} + \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\Phi^{c}\\Phi^{-1}\\dot{\\Phi}^c \\rp^\\vee \\\\\n",
    "&=& \\lp\\Phi^c\\Phi^{-1} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\dot{\\Phi} - \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\Phi^{c}\\Phi^{-1}\\dot{\\Phi}^c\\rp^\\vee\n",
    "\\label{eq:phitilde_dynamics}\n",
    "\\end{eqnarray}\n",
    "\n",
    "Now we have our error state dynamics in terms of the current state of our system and the commanded state\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{pmatrix} \\dot{\\tilde{\\Phi}} \n",
    "        \\\\ \\dot{\\tilde{\\omega}} \\end{pmatrix} \n",
    "    &=& \\begin{pmatrix} \\lp\\Phi^c\\Phi^{-1} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\dot{\\Phi} - \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\Phi^{c}\\Phi^{-1}\\dot{\\Phi}^c\\rp^\\vee\n",
    "        \\\\ \\dot{\\omega} - \\dot{\\omega}^c \\end{pmatrix}\n",
    "\\end{eqnarray}\n",
    "\n",
    "In a little bit, we will linearize our system either about the commanded or current state.  Either way works, but for this system I will put it in terms of the current state.  Before we can linearize, however, we must refactor the system in terms of the error state and current state.  If we wanted to linearize about the commanded state, we would instead remove the current state from the dynamics.\n",
    "\n",
    "Let us now write our reference state as a function of the current state and the error state.\n",
    "\\begin{eqnarray}\n",
    "\\begin{pmatrix} \\tilde{\\Phi} \\\\ \\tilde{\\omega} \\end{pmatrix} &=& \\begin{pmatrix} \\log\\lp \\Phi^c \\circ \\Phi^{-1} \\rp^\\vee \n",
    "        \\\\ \\omega - \\omega^c \\end{pmatrix} \\nonumber \\\\\n",
    "\\begin{pmatrix} \\exp\\lp\\tilde{\\Phi}\\rp \\\\ \\tilde{\\omega} -\\omega \\end{pmatrix} &=& \\begin{pmatrix} \\Phi^c \\circ \\Phi^{-1} \n",
    "        \\\\ - \\omega^c \\end{pmatrix} \\nonumber\\\\\n",
    "\\begin{pmatrix} \\exp\\lp\\tilde{\\Phi}\\rp \\circ \\Phi \\\\ \\omega - \\tilde{\\omega}  \\end{pmatrix} &=& \\begin{pmatrix} \\Phi^c \n",
    "        \\\\  \\omega^c \\end{pmatrix}\n",
    "        \\label{eq:ref_as_err_and_current}\n",
    "\\end{eqnarray}\n",
    "\n",
    "If we plug this into the dynamics equations, we get\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\begin{pmatrix} \\dot{\\tilde{\\Phi}} \n",
    "        \\\\ \\dot{\\tilde{\\omega}} \\end{pmatrix} \n",
    "    &=& \\begin{pmatrix} \\lp\\lp\\exp\\lp\\tilde{\\Phi}\\rp \\circ \\Phi\\rp\\Phi^{-1} \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\omega^\\wedge - \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\lp\\exp\\lp\\tilde{\\Phi}\\rp \\circ \\Phi\\rp\\Phi^{-1}\\lp\\omega - \\tilde{\\omega}\\rp^\\wedge\\rp^\\vee\n",
    "        \\\\ \\dot{\\tilde{\\omega}} \\end{pmatrix} \\nonumber \\\\\n",
    "        &=& \\begin{pmatrix} \\lp\\exp\\lp\\tilde{\\Phi}\\rp \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\omega^\\wedge - \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}\\exp\\lp\\tilde{\\Phi}\\rp\\lp\\omega - \\tilde{\\omega}\\rp^\\wedge\\rp^\\vee\n",
    "        \\\\ \\dot{\\tilde{\\omega}} \\end{pmatrix} \\\\\n",
    "        \\label{eq:error_state_dynamics}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need one more partial in order to solve \\eqref{eq:error_state_dynamics}\n",
    "\n",
    "$\\newcommand{dd}[1]{\\frac{\\partial}{\\partial #1}}$\n",
    "$\\newcommand{J}{\\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}}$\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dd{\\delta} \\exp\\lp{\\delta^\\wedge}\\rp &=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\\lp\\exp\\lp{\\delta^\\wedge + \\epsilon^\\wedge}\\rp - \\exp\\lp{\\delta^\\wedge}\\rp\\rp \\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon}\n",
    "\\lp\\exp\\lp{\\delta + \\epsilon}\\rp - \\exp\\lp{\\delta + \\epsilon}\\rp\\rp \\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \n",
    "\\lp\n",
    "\\begin{bmatrix}\\cos\\lp\\delta+\\epsilon\\rp & -\\sin\\lp\\delta+\\epsilon\\rp \\\\ \\sin\\lp\\delta+\\epsilon\\rp & \\cos\\lp\\delta+\\epsilon\\rp \\end{bmatrix}\n",
    "- \\begin{bmatrix}\\cos\\delta & -\\sin\\delta \\\\ \\sin\\delta & \\cos\\delta \\end{bmatrix}\n",
    "\\rp\\\\\n",
    "&=& \\lim_{\\epsilon \\to 0} \\frac{1}{\\epsilon} \n",
    "\\lp\n",
    "\\begin{bmatrix}\\cos\\lp\\delta+\\epsilon\\rp - \\cos\\delta & -\\sin\\lp\\delta+\\epsilon\\rp + \\sin\\delta \\\\ \\sin\\lp\\delta+\\epsilon\\rp - \\sin\\delta & \\cos\\lp\\delta+\\epsilon\\rp - \\cos\\delta \\end{bmatrix}\n",
    "\\rp\\\\\n",
    "&=& \n",
    "\\begin{bmatrix}-\\sin\\delta & -\\cos\\delta \\\\ \\cos\\delta & -\\sin\\delta \\end{bmatrix} \\\\\n",
    "&=& \\J \\exp\\delta^\\wedge\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Jacobian is Correct\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-8\n",
    "\n",
    "for i in range(100):\n",
    "    delta = np.random.random()\n",
    "    analytical = np.array([[0, -1], [1, 0]]).dot(SO2.exp(SO2.hat(delta)).mat)\n",
    "    x0 = SO2.exp(SO2.hat(delta)).mat\n",
    "    xi = SO2.exp(SO2.hat(delta+epsilon)).mat\n",
    "    finite_difference = (xi - x0)/epsilon\n",
    "    assert np.sum(np.abs(analytical - finite_difference)) < 1e-6, \"Analytical Jacobian Doesn't Match Numerical\"\n",
    "print \"Analytical Jacobian is Correct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can linearize our dynamics about our current state\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\dd{\\x} f\\lp\\x, \\u \\rp \n",
    "&=& \n",
    "\\begin{pmatrix} \n",
    "\\dd{\\tilde{\\Phi}} \\lp\\exp\\lp\\tilde{\\Phi}\\rp \\J\\omega^\\wedge - \\J\\exp\\lp\\tilde{\\Phi}\\rp\\lp\\omega - \\tilde{\\omega}\\rp^\\wedge\\rp^\\vee &\n",
    "\\dd{\\tilde{\\omega}} \\lp\\exp\\lp\\tilde{\\Phi}\\rp \\J\\omega^\\wedge - \\J\\exp\\lp\\tilde{\\Phi}\\rp\\lp\\omega - \\tilde{\\omega}\\rp^\\wedge\\rp^\\vee\n",
    "\\\\ \n",
    "\\dd{\\tilde{\\Phi}} \\dot{\\tilde{\\omega}} &\n",
    "\\dd{\\tilde{\\omega}} \\dot{\\tilde{\\omega}} &\n",
    "\\end{pmatrix} \\\\\n",
    "&=& \n",
    "\\begin{pmatrix} \n",
    "\\lp\\J\\exp\\lp\\tilde{\\Phi}\\rp\\J\\omega^\\wedge - \\J\\lp\\omega - \\tilde{\\omega}\\rp^\\wedge\\rp^\\vee &\n",
    "\\dd{\\tilde{\\omega}} \\lp \\J\\exp\\lp\\tilde{\\Phi}\\rp \\tilde{\\omega}^\\wedge\\rp^\\vee\n",
    "\\\\ \n",
    "0 & 0\n",
    "\\end{pmatrix} \\\\\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.88528185 -0.46505489]\n",
      " [ 0.46505489  0.88528185]]\n",
      "[[-0.46505489 -0.88528185]\n",
      " [ 0.88528185 -0.46505489]]\n"
     ]
    }
   ],
   "source": [
    "A = SO2.exp(SO2.hat(np.random.random()))\n",
    "print A\n",
    "J = np.array([[0, -1],[1, 0]])\n",
    "print J.dot(A.mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-0.8991587363560427\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Analytical Jacobian Doesn't Match Numerical",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-dca57fa14c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0manalytical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfinite_difference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalytical\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfinite_difference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Analytical Jacobian Doesn't Match Numerical\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# DPhidot/domega\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Analytical Jacobian Doesn't Match Numerical"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-8\n",
    "J = np.array([[0, -1], [1, 0]])\n",
    "\n",
    "# DPhidot/dPhi\n",
    "for i in range(100):\n",
    "    Phit = np.random.random()\n",
    "    wt = np.random.random()\n",
    "    w = np.random.random()\n",
    "    \n",
    "\n",
    "    analytical = SO2.vee(J.dot(SO2.hat(w)) - J.dot(SO2.hat(w - wt)))\n",
    "    x0 = SO2.vee(J.dot(SO2.exp(SO2.hat(Phit)).mat.dot(SO2.hat(wt))))\n",
    "    xi = SO2.vee(J.dot(SO2.exp(SO2.hat(Phit+epsilon)).mat.dot(SO2.hat(wt))))\n",
    "    finite_difference = (xi - x0)/epsilon\n",
    "    print analytical\n",
    "    print finite_difference\n",
    "    assert np.sum(np.abs(analytical - finite_difference)) < 1e-6, \"Analytical Jacobian Doesn't Match Numerical\"\n",
    "\n",
    "# DPhidot/domega\n",
    "for i in range(100):\n",
    "    wt = np.random.random()\n",
    "    Phit = np.random.random()\n",
    "\n",
    "    analytical = SO2.vee(-SO2.exp(SO2.hat(Phit)).mat)\n",
    "    x0 = SO2.vee(J.dot(SO2.exp(SO2.hat(Phit)).mat.dot(SO2.hat(wt))))\n",
    "    xi = SO2.vee(J.dot(SO2.exp(SO2.hat(Phit)).mat.dot(SO2.hat(wt + epsilon))))\n",
    "    finite_difference = (xi - x0)/epsilon\n",
    "    assert np.sum(np.abs(analytical - finite_difference)) < 1e-6, \"Analytical Jacobian Doesn't Match Numerical\"\n",
    "print \"Analytical Jacobian is Correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.random.random((2,2))\n",
    "print m\n",
    "v = np.array([[1, 0]]).T\n",
    "n = np.array([[0, 1]]).T\n",
    "print v.T.dot(m.dot(v))\n",
    "print n.T.dot(m.dot(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "\n",
    "Devon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
